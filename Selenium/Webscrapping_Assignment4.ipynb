{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "### Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "### You need to find following details:\n",
    "\n",
    "A) Rank <tr>\n",
    "    \n",
    "B) Name <tr>\n",
    "    \n",
    "C) Artist <tr>\n",
    "    \n",
    "D) Upload date <tr>\n",
    "    \n",
    "E) Views <tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_1356\\3672835477.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1 = driver.find_element_by_xpath('//*[@id=\"noarticletext\"]/tbody/tr/td/span/a')       # Locating page for top videos by xpath\n",
    "search_1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_2 = driver.find_element_by_xpath('//*[@id=\"mw-content-text\"]/div[3]/ul/li[1]/div[1]/a')       # Locating page for top youtube videos by xpath\n",
    "search_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', '13.', '14.', '15.', '16.', '17.', '18.', '19.', '20.', '21.', '22.', '23.', '24.', '25.', '26.', '27.', '28.', '29.', '30.']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "rk=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[1]\")\n",
    "for i in rk:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['\"Baby Shark Dance\"[28]', '\"Despacito\"[30]', '\"Shape of You\"[31]', '\"See You Again\"[32]', '\"Johny Johny Yes Papa\"[35]', '\"Masha and the Bear – Recipe for Disaster\"[36]', '\"Uptown Funk\"[37]', '\"Gangnam Style\"[38]', '\"Learning Colors – Colorful Eggs on a Farm\"[40]', '\"Bath Song\"[41]', '\"Phonics Song with Two Words\"[42]', '\"Sorry\"[43]', '\"Sugar\"[44]', '\"Roar\"[45]', '\"Counting Stars\"[46]', '\"Thinking Out Loud\"[47]', '\"Dame Tu Cosita\"[48]', '\"Shake It Off\"[49]', '\"Faded\"[50]', '\"Lean On\"[51]', '\"Bailando\"[52]', '\"Dark Horse\"[53]', '\"Girls Like You\"[54]', '\"Let Her Go\"[55]', '\"Mi Gente\"[56]', '\"Hello\"[57]', '\"Perfect\"[58]', '\"Waka Waka (This Time for Africa)\"[59]', '\"Blank Space\"[60]', '\"Chantaje\"[61]']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Video Name \n",
    "nm=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[2]\")\n",
    "for i in nm:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "print(len(Name),Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 [\"Pinkfong Kids' Songs & Stories\", 'Luis Fonsi featuring Daddy Yankee', 'Ed Sheeran', 'Wiz Khalifa featuring Charlie Puth', 'LooLoo Kids', 'Get Movies', 'Mark Ronson featuring Bruno Mars', 'Psy', 'Miroshka TV', 'Cocomelon – Nursery Rhymes', 'ChuChu TV', 'Justin Bieber', 'Maroon 5', 'Katy Perry', 'OneRepublic', 'Ed Sheeran', 'El Chombo featuring Cutty Ranks', 'Taylor Swift', 'Alan Walker', 'Major Lazer and DJ Snake featuring MØ', 'Enrique Iglesias featuring Descemer Bueno and Gente De Zona', 'Katy Perry featuring Juicy J', 'Maroon 5 featuring Cardi B', 'Passenger', 'J Balvin and Willy William', 'Adele', 'Ed Sheeran', 'Shakira featuring Freshlyground', 'Taylor Swift', 'Shakira featuring Maluma']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Artist \n",
    "Ar=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[3]\")\n",
    "for i in Ar:\n",
    "    if i.text is None :\n",
    "        Artist.append(\"--\") \n",
    "    else:\n",
    "        Artist.append(i.text)\n",
    "print(len(Artist),Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['June 17, 2016', 'January 12, 2017', 'January 30, 2017', 'April 6, 2015', 'October 8, 2016', 'January 31, 2012', 'November 19, 2014', 'July 15, 2012', 'February 27, 2018', 'May 2, 2018', 'March 6, 2014', 'October 22, 2015', 'January 14, 2015', 'September 5, 2013', 'May 31, 2013', 'October 7, 2014', 'April 5, 2018', 'August 18, 2014', 'December 3, 2015', 'March 22, 2015', 'April 11, 2014', 'February 20, 2014', 'May 31, 2018', 'July 25, 2012', 'June 29, 2017', 'October 22, 2015', 'November 9, 2017', 'June 4, 2010', 'November 10, 2014', 'November 18, 2016']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Upload_Date \n",
    "date=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[5]\")\n",
    "for i in date:\n",
    "    if i.text is None :\n",
    "        Upload_Date.append(\"--\") \n",
    "    else:\n",
    "        Upload_Date.append(i.text)\n",
    "print(len(Upload_Date),Upload_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['7.91', '7.20', '5.18', '4.96', '4.77', '4.41', '4.09', '3.97', '3.69', '3.64', '3.53', '3.40', '3.39', '3.27', '3.19', '3.18', '3.11', '3.02', '2.98', '2.97', '2.97', '2.97', '2.96', '2.91', '2.86', '2.79', '2.74', '2.74', '2.72', '2.62']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Views \n",
    "v=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[4]\")\n",
    "for i in v:\n",
    "    if i.text is None :\n",
    "        Views.append(\"--\") \n",
    "    else:\n",
    "        Views.append(i.text)\n",
    "print(len(Views),Views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views In Bllion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[28]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[30]</td>\n",
       "      <td>Luis Fonsi featuring Daddy Yankee</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Shape of You\"[31]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"See You Again\"[32]</td>\n",
       "      <td>Wiz Khalifa featuring Charlie Puth</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[35]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"[37]</td>\n",
       "      <td>Mark Ronson featuring Bruno Mars</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Gangnam Style\"[38]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[40]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Bath Song\"[41]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[42]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sorry\"[43]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sugar\"[44]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Roar\"[45]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Counting Stars\"[46]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Thinking Out Loud\"[47]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Dame Tu Cosita\"[48]</td>\n",
       "      <td>El Chombo featuring Cutty Ranks</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Shake It Off\"[49]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"[50]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lean On\"[51]</td>\n",
       "      <td>Major Lazer and DJ Snake featuring MØ</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>Enrique Iglesias featuring Descemer Bueno and ...</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[53]</td>\n",
       "      <td>Katy Perry featuring Juicy J</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5 featuring Cardi B</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[55]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Mi Gente\"[56]</td>\n",
       "      <td>J Balvin and Willy William</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Hello\"[57]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[58]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[59]</td>\n",
       "      <td>Shakira featuring Freshlyground</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Blank Space\"[60]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>November 10, 2014</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Chantaje\"[61]</td>\n",
       "      <td>Shakira featuring Maluma</td>\n",
       "      <td>November 18, 2016</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                      Video Title  \\\n",
       "0    1.                           \"Baby Shark Dance\"[28]   \n",
       "1    2.                                  \"Despacito\"[30]   \n",
       "2    3.                               \"Shape of You\"[31]   \n",
       "3    4.                              \"See You Again\"[32]   \n",
       "4    5.                       \"Johny Johny Yes Papa\"[35]   \n",
       "5    6.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "6    7.                                \"Uptown Funk\"[37]   \n",
       "7    8.                              \"Gangnam Style\"[38]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[40]   \n",
       "9   10.                                  \"Bath Song\"[41]   \n",
       "10  11.                \"Phonics Song with Two Words\"[42]   \n",
       "11  12.                                      \"Sorry\"[43]   \n",
       "12  13.                                      \"Sugar\"[44]   \n",
       "13  14.                                       \"Roar\"[45]   \n",
       "14  15.                             \"Counting Stars\"[46]   \n",
       "15  16.                          \"Thinking Out Loud\"[47]   \n",
       "16  17.                             \"Dame Tu Cosita\"[48]   \n",
       "17  18.                               \"Shake It Off\"[49]   \n",
       "18  19.                                      \"Faded\"[50]   \n",
       "19  20.                                    \"Lean On\"[51]   \n",
       "20  21.                                   \"Bailando\"[52]   \n",
       "21  22.                                 \"Dark Horse\"[53]   \n",
       "22  23.                             \"Girls Like You\"[54]   \n",
       "23  24.                                 \"Let Her Go\"[55]   \n",
       "24  25.                                   \"Mi Gente\"[56]   \n",
       "25  26.                                      \"Hello\"[57]   \n",
       "26  27.                                    \"Perfect\"[58]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[59]   \n",
       "28  29.                                \"Blank Space\"[60]   \n",
       "29  30.                                   \"Chantaje\"[61]   \n",
       "\n",
       "                                               Artist        Upload_Date  \\\n",
       "0                      Pinkfong Kids' Songs & Stories      June 17, 2016   \n",
       "1                   Luis Fonsi featuring Daddy Yankee   January 12, 2017   \n",
       "2                                          Ed Sheeran   January 30, 2017   \n",
       "3                  Wiz Khalifa featuring Charlie Puth      April 6, 2015   \n",
       "4                                         LooLoo Kids    October 8, 2016   \n",
       "5                                          Get Movies   January 31, 2012   \n",
       "6                    Mark Ronson featuring Bruno Mars  November 19, 2014   \n",
       "7                                                 Psy      July 15, 2012   \n",
       "8                                         Miroshka TV  February 27, 2018   \n",
       "9                          Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "10                                          ChuChu TV      March 6, 2014   \n",
       "11                                      Justin Bieber   October 22, 2015   \n",
       "12                                           Maroon 5   January 14, 2015   \n",
       "13                                         Katy Perry  September 5, 2013   \n",
       "14                                        OneRepublic       May 31, 2013   \n",
       "15                                         Ed Sheeran    October 7, 2014   \n",
       "16                    El Chombo featuring Cutty Ranks      April 5, 2018   \n",
       "17                                       Taylor Swift    August 18, 2014   \n",
       "18                                        Alan Walker   December 3, 2015   \n",
       "19              Major Lazer and DJ Snake featuring MØ     March 22, 2015   \n",
       "20  Enrique Iglesias featuring Descemer Bueno and ...     April 11, 2014   \n",
       "21                       Katy Perry featuring Juicy J  February 20, 2014   \n",
       "22                         Maroon 5 featuring Cardi B       May 31, 2018   \n",
       "23                                          Passenger      July 25, 2012   \n",
       "24                         J Balvin and Willy William      June 29, 2017   \n",
       "25                                              Adele   October 22, 2015   \n",
       "26                                         Ed Sheeran   November 9, 2017   \n",
       "27                    Shakira featuring Freshlyground       June 4, 2010   \n",
       "28                                       Taylor Swift  November 10, 2014   \n",
       "29                           Shakira featuring Maluma  November 18, 2016   \n",
       "\n",
       "   Views In Bllion  \n",
       "0             7.91  \n",
       "1             7.20  \n",
       "2             5.18  \n",
       "3             4.96  \n",
       "4             4.77  \n",
       "5             4.41  \n",
       "6             4.09  \n",
       "7             3.97  \n",
       "8             3.69  \n",
       "9             3.64  \n",
       "10            3.53  \n",
       "11            3.40  \n",
       "12            3.39  \n",
       "13            3.27  \n",
       "14            3.19  \n",
       "15            3.18  \n",
       "16            3.11  \n",
       "17            3.02  \n",
       "18            2.98  \n",
       "19            2.97  \n",
       "20            2.97  \n",
       "21            2.97  \n",
       "22            2.96  \n",
       "23            2.91  \n",
       "24            2.86  \n",
       "25            2.79  \n",
       "26            2.74  \n",
       "27            2.74  \n",
       "28            2.72  \n",
       "29            2.62  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube_Video=pd.DataFrame([])\n",
    "Youtube_Video['Rank']=Rank\n",
    "Youtube_Video['Video Title']=Name\n",
    "Youtube_Video['Artist']=Artist\n",
    "Youtube_Video['Upload_Date']=Upload_Date\n",
    "Youtube_Video['Views In Bllion']=Views\n",
    "Youtube_Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_10860\\281109501.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2=\"https://www.bcci.tv/international/fixtures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Team=[]\n",
    "Date_Time =[]\n",
    "Ground=[]\n",
    "Test_ODI=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['INDIA\\nENGLAND\\nLIVE', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA']\n"
     ]
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "tm=driver.find_elements_by_xpath(\"//div[@class='fixture__teams']\")\n",
    "for i in tm:\n",
    "    if i.text is None :\n",
    "        Team.append(\"--\") \n",
    "    else:\n",
    "        Team.append(i.text)\n",
    "print(len(Team),Team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['Saturday 13 February 09:30 IST', 'Wednesday 24 February 14:30 IST', 'Thursday 4 March 09:30 IST', 'Friday 12 March 19:00 IST', 'Sunday 14 March 19:00 IST', 'Tuesday 16 March 19:00 IST', 'Thursday 18 March 19:00 IST', 'Saturday 20 March 19:00 IST', 'Tuesday 23 March 13:30 IST', 'Friday 26 March 13:30 IST', 'Sunday 28 March 13:30 IST', 'Wednesday 4 August 15:30 IST', 'Thursday 12 August 15:30 IST', 'Wednesday 25 August 15:30 IST', 'Thursday 2 September 15:30 IST', 'Friday 10 September 15:30 IST']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Date_Time \n",
    "DT=driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']\")\n",
    "for i in DT:\n",
    "    if i.text is None :\n",
    "        Date_Time.append(\"--\") \n",
    "    else:\n",
    "        Date_Time.append(i.text)\n",
    "print(len(Date_Time),Date_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['M. A. Chidambaram Stadium, Chennai', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Maharashtra Cricket Association Stadium, Pune', 'Maharashtra Cricket Association Stadium, Pune', 'Maharashtra Cricket Association Stadium, Pune', 'Trent Bridge, Nottingham', \"Lord's, London\", 'Headingley, Leeds', 'The Oval, London', 'Old Trafford, Manchester']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Ground \n",
    "G=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "for i in G:\n",
    "    if i.text is None :\n",
    "        Ground.append(\"--\") \n",
    "    else:\n",
    "        Ground.append(i.text)\n",
    "print(len(Ground),Ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['2nd Test', '3rd Test', '4th Test', '1st T20I', '2nd T20I', '3rd T20I', '4th T20I', '5th T20I', '1st ODI', '2nd ODI', '3rd ODI', '1st Test', '2nd Test', '3rd Test', '4th Test', '5th Test']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Test_ODI \n",
    "TO=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/strong\")\n",
    "for i in TO:\n",
    "    if i.text is None :\n",
    "        Test_ODI.append(\"--\") \n",
    "    else:\n",
    "        Test_ODI.append(i.text)\n",
    "print(len(Test_ODI),Test_ODI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Ground</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA\\nENGLAND\\nLIVE</td>\n",
       "      <td>Saturday 13 February 09:30 IST</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>M. A. Chidambaram Stadium, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Wednesday 24 February 14:30 IST</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Thursday 4 March 09:30 IST</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Friday 12 March 19:00 IST</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Sunday 14 March 19:00 IST</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Tuesday 16 March 19:00 IST</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Thursday 18 March 19:00 IST</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Saturday 20 March 19:00 IST</td>\n",
       "      <td>5th T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Tuesday 23 March 13:30 IST</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Friday 26 March 13:30 IST</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Sunday 28 March 13:30 IST</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Wednesday 4 August 15:30 IST</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Thursday 12 August 15:30 IST</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Lord's, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Wednesday 25 August 15:30 IST</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Thursday 2 September 15:30 IST</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>The Oval, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Friday 10 September 15:30 IST</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Team                        Date_Time    Series  \\\n",
       "0   INDIA\\nENGLAND\\nLIVE   Saturday 13 February 09:30 IST  2nd Test   \n",
       "1         INDIA\\nENGLAND  Wednesday 24 February 14:30 IST  3rd Test   \n",
       "2         INDIA\\nENGLAND       Thursday 4 March 09:30 IST  4th Test   \n",
       "3         INDIA\\nENGLAND        Friday 12 March 19:00 IST  1st T20I   \n",
       "4         INDIA\\nENGLAND        Sunday 14 March 19:00 IST  2nd T20I   \n",
       "5         INDIA\\nENGLAND       Tuesday 16 March 19:00 IST  3rd T20I   \n",
       "6         INDIA\\nENGLAND      Thursday 18 March 19:00 IST  4th T20I   \n",
       "7         INDIA\\nENGLAND      Saturday 20 March 19:00 IST  5th T20I   \n",
       "8         INDIA\\nENGLAND       Tuesday 23 March 13:30 IST   1st ODI   \n",
       "9         INDIA\\nENGLAND        Friday 26 March 13:30 IST   2nd ODI   \n",
       "10        INDIA\\nENGLAND        Sunday 28 March 13:30 IST   3rd ODI   \n",
       "11        ENGLAND\\nINDIA     Wednesday 4 August 15:30 IST  1st Test   \n",
       "12        ENGLAND\\nINDIA     Thursday 12 August 15:30 IST  2nd Test   \n",
       "13        ENGLAND\\nINDIA    Wednesday 25 August 15:30 IST  3rd Test   \n",
       "14        ENGLAND\\nINDIA   Thursday 2 September 15:30 IST  4th Test   \n",
       "15        ENGLAND\\nINDIA    Friday 10 September 15:30 IST  5th Test   \n",
       "\n",
       "                                           Ground  \n",
       "0              M. A. Chidambaram Stadium, Chennai  \n",
       "1                 Sardar Patel Stadium, Ahmedabad  \n",
       "2                 Sardar Patel Stadium, Ahmedabad  \n",
       "3                 Sardar Patel Stadium, Ahmedabad  \n",
       "4                 Sardar Patel Stadium, Ahmedabad  \n",
       "5                 Sardar Patel Stadium, Ahmedabad  \n",
       "6                 Sardar Patel Stadium, Ahmedabad  \n",
       "7                 Sardar Patel Stadium, Ahmedabad  \n",
       "8   Maharashtra Cricket Association Stadium, Pune  \n",
       "9   Maharashtra Cricket Association Stadium, Pune  \n",
       "10  Maharashtra Cricket Association Stadium, Pune  \n",
       "11                       Trent Bridge, Nottingham  \n",
       "12                                 Lord's, London  \n",
       "13                              Headingley, Leeds  \n",
       "14                               The Oval, London  \n",
       "15                       Old Trafford, Manchester  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "International_Fixtures=pd.DataFrame([])\n",
    "International_Fixtures['Team']=Team\n",
    "International_Fixtures['Date_Time']=Date_Time\n",
    "International_Fixtures['Series']=Test_ODI\n",
    "International_Fixtures['Ground']=Ground\n",
    "International_Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_10860\\281109501.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3=\"http://statisticstimes.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State =[]\n",
    "GDP=[]\n",
    "GSDP_Current=[]\n",
    "GSDP_Previous=[]\n",
    "Share=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/button')       \n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')       \n",
    "ind.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')     \n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "r=driver.find_elements_by_xpath(\"//td[@class='data1']\")\n",
    "for i in r:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['Maharashtra', 'Uttar Pradesh', 'Tamil Nadu', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India', 'Maharashtra', 'Uttar Pradesh', 'Tamil Nadu', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Telangana', 'Andhra Pradesh', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Jharkhand', 'Chhattisgarh', 'Uttarakhand', 'Himachal Pradesh', 'Jammu & Kashmir', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Manipur', 'Sikkim', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India']\n"
     ]
    }
   ],
   "source": [
    "#scraping the State \n",
    "St=driver.find_elements_by_xpath(\"//td[@class='name']\")\n",
    "for i in St:\n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "print(len(State),State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['398.145', '252.278', '246.529', '233.552', '227.276', '164.820', '142.543', '130.501', '130.210', '122.431', '118.206', '117.180', '111.024', '80.204', '79.601', '74.437', '47.769', '45.982', '44.945', '37.186', '23.584', '23.265', '11.065', '7.538', '6.369', '5.543', '5.063', '4.344', '4.214', '4.126', '3.721', '2.952', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GDP \n",
    "gdp=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    if i.text is None :\n",
    "        GDP.append(\"--\") \n",
    "    else:\n",
    "        GDP.append(i.text)\n",
    "print(len(GDP),GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['13.88%', '8.79%', '8.59%', '8.14%', '7.92%', '5.75%', '4.97%', '4.55%', '4.54%', '4.27%', '4.12%', '4.08%', '3.87%', '2.80%', '2.77%', '2.59%', '1.67%', '1.60%', '1.57%', '1.30%', '0.82%', '0.81%', '0.39%', '0.26%', '0.22%', '0.19%', '0.18%', '0.15%', '0.15%', '0.14%', '0.13%', '0.10%', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Share \n",
    "shr=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        Share.append(\"--\") \n",
    "    else:\n",
    "        Share.append(i.text)\n",
    "print(len(Share),Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,632,792', '1,668,229', '1,630,208', '1,544,399', '1,502,899', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '492,229', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '36,656', '33,481', '28,723', '27,869', '27,283', '24,603', '19,520', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Current \n",
    "shr=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Current.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Current.append(i.text)\n",
    "print(len(GSDP_Current),GSDP_Current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,039,074', '1,137,469', '1,215,307', '1,124,423', '1,186,379', '739,525', '677,428', '621,301', '612,828', '522,009', '559,412', '590,569', '531,085', '375,651', '397,669', '382,218', '234,048', '231,182', '224,986', '193,273', '112,755', '117,851', '62,539', '36,963', '31,192', '24,442', '24,682', '18,722', '19,300', '17,647', '16,676', '14,524', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Previous \n",
    "shr=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[8]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Previous.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Previous.append(i.text)\n",
    "print(len(GSDP_Previous),GSDP_Previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share In GDP</th>\n",
       "      <th>GDP of State</th>\n",
       "      <th>GSDP_Current</th>\n",
       "      <th>GSDP_Previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>13.88%</td>\n",
       "      <td>398.145</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>2,039,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>8.79%</td>\n",
       "      <td>252.278</td>\n",
       "      <td>1,668,229</td>\n",
       "      <td>1,137,469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.59%</td>\n",
       "      <td>246.529</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,215,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>233.552</td>\n",
       "      <td>1,544,399</td>\n",
       "      <td>1,124,423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>7.92%</td>\n",
       "      <td>227.276</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>1,186,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>5.75%</td>\n",
       "      <td>164.820</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>739,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>4.97%</td>\n",
       "      <td>142.543</td>\n",
       "      <td>942,586</td>\n",
       "      <td>677,428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.55%</td>\n",
       "      <td>130.501</td>\n",
       "      <td>862,957</td>\n",
       "      <td>621,301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>4.54%</td>\n",
       "      <td>130.210</td>\n",
       "      <td>861,031</td>\n",
       "      <td>612,828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>4.27%</td>\n",
       "      <td>122.431</td>\n",
       "      <td>809,592</td>\n",
       "      <td>522,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4.12%</td>\n",
       "      <td>118.206</td>\n",
       "      <td>781,653</td>\n",
       "      <td>559,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>4.08%</td>\n",
       "      <td>117.180</td>\n",
       "      <td>774,870</td>\n",
       "      <td>590,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>111.024</td>\n",
       "      <td>734,163</td>\n",
       "      <td>531,085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.80%</td>\n",
       "      <td>80.204</td>\n",
       "      <td>530,363</td>\n",
       "      <td>375,651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>79.601</td>\n",
       "      <td>526,376</td>\n",
       "      <td>397,669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2.59%</td>\n",
       "      <td>74.437</td>\n",
       "      <td>492,229</td>\n",
       "      <td>382,218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.769</td>\n",
       "      <td>315,881</td>\n",
       "      <td>234,048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>45.982</td>\n",
       "      <td>304,063</td>\n",
       "      <td>231,182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>44.945</td>\n",
       "      <td>297,204</td>\n",
       "      <td>224,986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.186</td>\n",
       "      <td>245,895</td>\n",
       "      <td>193,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>23.584</td>\n",
       "      <td>155,956</td>\n",
       "      <td>112,755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.265</td>\n",
       "      <td>153,845</td>\n",
       "      <td>117,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.065</td>\n",
       "      <td>73,170</td>\n",
       "      <td>62,539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.538</td>\n",
       "      <td>49,845</td>\n",
       "      <td>36,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.369</td>\n",
       "      <td>42,114</td>\n",
       "      <td>31,192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.543</td>\n",
       "      <td>36,656</td>\n",
       "      <td>24,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.063</td>\n",
       "      <td>33,481</td>\n",
       "      <td>24,682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.344</td>\n",
       "      <td>28,723</td>\n",
       "      <td>18,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.214</td>\n",
       "      <td>27,869</td>\n",
       "      <td>19,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.126</td>\n",
       "      <td>27,283</td>\n",
       "      <td>17,647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.721</td>\n",
       "      <td>24,603</td>\n",
       "      <td>16,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>0.10%</td>\n",
       "      <td>2.952</td>\n",
       "      <td>19,520</td>\n",
       "      <td>14,524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Share In GDP GDP of State GSDP_Current  \\\n",
       "0     1                Maharashtra       13.88%      398.145    2,632,792   \n",
       "1     2              Uttar Pradesh        8.79%      252.278    1,668,229   \n",
       "2     3                 Tamil Nadu        8.59%      246.529    1,630,208   \n",
       "3     4                  Karnataka        8.14%      233.552    1,544,399   \n",
       "4     5                    Gujarat        7.92%      227.276    1,502,899   \n",
       "5     6                West Bengal        5.75%      164.820    1,089,898   \n",
       "6     7                  Rajasthan        4.97%      142.543      942,586   \n",
       "7     8             Andhra Pradesh        4.55%      130.501      862,957   \n",
       "8     9                  Telangana        4.54%      130.210      861,031   \n",
       "9    10             Madhya Pradesh        4.27%      122.431      809,592   \n",
       "10   11                     Kerala        4.12%      118.206      781,653   \n",
       "11   12                      Delhi        4.08%      117.180      774,870   \n",
       "12   13                    Haryana        3.87%      111.024      734,163   \n",
       "13   14                      Bihar        2.80%       80.204      530,363   \n",
       "14   15                     Punjab        2.77%       79.601      526,376   \n",
       "15   16                     Odisha        2.59%       74.437      492,229   \n",
       "16   17                      Assam        1.67%       47.769      315,881   \n",
       "17   18               Chhattisgarh        1.60%       45.982      304,063   \n",
       "18   19                  Jharkhand        1.57%       44.945      297,204   \n",
       "19   20                Uttarakhand        1.30%       37.186      245,895   \n",
       "20   21            Jammu & Kashmir        0.82%       23.584      155,956   \n",
       "21   22           Himachal Pradesh        0.81%       23.265      153,845   \n",
       "22   23                        Goa        0.39%       11.065       73,170   \n",
       "23   24                    Tripura        0.26%        7.538       49,845   \n",
       "24   25                 Chandigarh        0.22%        6.369       42,114   \n",
       "25   26                 Puducherry        0.19%        5.543       36,656   \n",
       "26   27                  Meghalaya        0.18%        5.063       33,481   \n",
       "27   28                     Sikkim        0.15%        4.344       28,723   \n",
       "28   29                    Manipur        0.15%        4.214       27,869   \n",
       "29   30                   Nagaland        0.14%        4.126       27,283   \n",
       "30   31          Arunachal Pradesh        0.13%        3.721       24,603   \n",
       "31   32                    Mizoram        0.10%        2.952       19,520   \n",
       "32   33  Andaman & Nicobar Islands            -            -            -   \n",
       "\n",
       "   GSDP_Previous  \n",
       "0      2,039,074  \n",
       "1      1,137,469  \n",
       "2      1,215,307  \n",
       "3      1,124,423  \n",
       "4      1,186,379  \n",
       "5        739,525  \n",
       "6        677,428  \n",
       "7        621,301  \n",
       "8        612,828  \n",
       "9        522,009  \n",
       "10       559,412  \n",
       "11       590,569  \n",
       "12       531,085  \n",
       "13       375,651  \n",
       "14       397,669  \n",
       "15       382,218  \n",
       "16       234,048  \n",
       "17       231,182  \n",
       "18       224,986  \n",
       "19       193,273  \n",
       "20       112,755  \n",
       "21       117,851  \n",
       "22        62,539  \n",
       "23        36,963  \n",
       "24        31,192  \n",
       "25        24,442  \n",
       "26        24,682  \n",
       "27        18,722  \n",
       "28        19,300  \n",
       "29        17,647  \n",
       "30        16,676  \n",
       "31        14,524  \n",
       "32             -  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State_GDP=pd.DataFrame([])\n",
    "State_GDP['Rank']=Rank[:33]\n",
    "State_GDP['State']=State[:33]\n",
    "State_GDP['Share In GDP']=Share[:33]\n",
    "State_GDP['GDP of State']=GDP[:33]\n",
    "State_GDP['GSDP_Current']=GSDP_Current[:33]\n",
    "State_GDP['GSDP_Previous']=GSDP_Previous[:33]\n",
    "State_GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_10860\\281109501.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_4=\"https://github.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_Name =[]\n",
    "Language=[]\n",
    "Muted_Link=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details')      \n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]')     \n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['libsdl-org /', 'Azure /', 'system76 /', 'benbjohnson /', 'mbround18 /', 'deepmind /', 'satwikkansal /', 'vlang /', 'serhii-londar /', 'PowerShell /', 'ossu /', 'iptv-org /', 'streamich /', 'Azure /', 'adityatelange /', 'reactend /', 'flybywiresim /', 'Dimbreath /', 'hashicorp /', 'abhishekkrthakur /', 'florisboard /', 'goreleaser /', 'donnemartin /', 'dotnet /', 'reed-hong /']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Repositor_Name \n",
    "RN=driver.find_elements_by_xpath(\"//span[@class='text-normal']\")\n",
    "for i in RN:\n",
    "    if i.text is None :\n",
    "        Repository_Name.append(\"--\") \n",
    "    else:\n",
    "        Repository_Name.append(i.text)\n",
    "print(len(Repository_Name),Repository_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['Simple Directmedia Layer', 'Azure Quickstart Templates', 'System76 Launch Configurable Keyboard', 'Streaming S3 replication for SQLite.', 'Valheim Docker server with Odin the CLI tool.', 'This repository contains implementations and illustrative code to accompany DeepMind publications', 'What the f*ck Python?', 'Simple, fast, safe, compiled language for developing maintainable software. Compiles itself in <1s with zero library dependencies. https://vlang.io', '🚀 Awesome list of open source applications for macOS. https://t.me/opensourcemacosapps', 'PowerShell for every system!', '🎓 Path to a free self-taught education in Computer Science!', 'Collection of 5000+ publicly available IPTV channels from all over the world', 'React Hooks — 👍', 'The source for REST API specifications for Microsoft Azure.', 'A fast, clean, responsive Hugo theme', 'React renderer to build Node.js server', 'The A32NX Project is a community driven open source project to create a free Airbus A320neo in Microsoft Flight Simulator that is as close to reality as possible. It aims to enhance the default A320neo by improving the systems depth and functionality to bring it up to payware-level, all for free.', 'Repository containing the game data for the game Genshin Impact.', 'A tool for secrets management, encryption as a service, and privileged access management', 'Run VSCode (codeserver) on Google Colab or Kaggle Notebooks', 'An open-source keyboard for Android. Currently in alpha/early-beta stage.', 'Deliver Go binaries as fast and easily as possible', 'Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.', 'ASP.NET Core is a cross-platform .NET framework for building modern cloud-based web applications on Windows, Mac, or Linux.', 'A Curated List of Awesome Facebook Libra Resources']\n"
     ]
    }
   ],
   "source": [
    "Description=[]\n",
    "#scraping the Description \n",
    "des=driver.find_elements_by_xpath(\"//p[@class='col-9 text-gray my-1 pr-4']\")\n",
    "for i in des:\n",
    "    if i.text is None :\n",
    "        Description.append(\"--\") \n",
    "    else:\n",
    "        Description.append(i.text)\n",
    "print(len(Description),Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ['C', 'PowerShell', 'Shell', 'Go', 'Rust', 'Jupyter Notebook', 'Python', 'V', 'Swift', 'C#', 'JavaScript', 'TypeScript', 'TypeScript', 'HTML', 'JavaScript', 'JavaScript', 'Go', 'Python', 'Kotlin', 'Go', 'Python', 'C#']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Language \n",
    "L=driver.find_elements_by_xpath(\"//span[@itemprop='programmingLanguage']\")\n",
    "for i in L:\n",
    "    if i.text is None :\n",
    "        Language.append(\"NAN\") \n",
    "    else:\n",
    "        Language.append(i.text)\n",
    "print(len(Language),Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['420', '22', '9,416', '12,234', '737', '14', '1,922', '32', '70', '12', '5,055', '978', '24,436', '2,095', '22,167', '1,326', '24,625', '1,648', '24,249', '3,923', '74,976', '10,823', '27,557', '861', '19,578', '1,373', '1,052', '2,649', '507', '230', '162', '8', '2,949', '466', '69', '20', '20,024', '2,793', '1,047', '144', '534', '48', '7,013', '503', '120,892', '22,004', '21,023', '6,006', '3,669', '167']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Muted_Link And Star \n",
    "ml=driver.find_elements_by_xpath(\"//a[@class='muted-link d-inline-block mr-3']\")\n",
    "for i in ml:\n",
    "    if i.text is None :\n",
    "        Muted_Link.append(\"NAN\") \n",
    "    else:\n",
    "        Muted_Link.append(i.text)\n",
    "print(len(Muted_Link),Muted_Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['22', '12,234', '14', '32', '12', '978', '2,095', '1,326', '1,648', '3,923', '10,823', '861', '1,373', '2,649', '230', '8', '466', '20', '2,793', '144', '48', '503', '22,004', '6,006', '167']\n"
     ]
    }
   ],
   "source": [
    "Muted=[]\n",
    "for i in range(1,len(Muted_Link),2):\n",
    "    Muted.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted),Muted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['420', '9,416', '737', '1,922', '70', '5,055', '24,436', '22,167', '24,625', '24,249', '74,976', '27,557', '19,578', '1,052', '507', '162', '2,949', '69', '20,024', '1,047', '534', '7,013', '120,892', '21,023', '3,669']\n"
     ]
    }
   ],
   "source": [
    "Muted_Star=[]\n",
    "for i in range(0,len(Muted_Link),2):\n",
    "    Muted_Star.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted_Star),Muted_Star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Conutrybuted</th>\n",
       "      <th>Muted_Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>libsdl-org /</td>\n",
       "      <td>Simple Directmedia Layer</td>\n",
       "      <td>C</td>\n",
       "      <td>22</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure /</td>\n",
       "      <td>Azure Quickstart Templates</td>\n",
       "      <td>PowerShell</td>\n",
       "      <td>12,234</td>\n",
       "      <td>9,416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system76 /</td>\n",
       "      <td>System76 Launch Configurable Keyboard</td>\n",
       "      <td>Shell</td>\n",
       "      <td>14</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benbjohnson /</td>\n",
       "      <td>Streaming S3 replication for SQLite.</td>\n",
       "      <td>Go</td>\n",
       "      <td>32</td>\n",
       "      <td>1,922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mbround18 /</td>\n",
       "      <td>Valheim Docker server with Odin the CLI tool.</td>\n",
       "      <td>Rust</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepmind /</td>\n",
       "      <td>This repository contains implementations and i...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>978</td>\n",
       "      <td>5,055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>satwikkansal /</td>\n",
       "      <td>What the f*ck Python?</td>\n",
       "      <td>Python</td>\n",
       "      <td>2,095</td>\n",
       "      <td>24,436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vlang /</td>\n",
       "      <td>Simple, fast, safe, compiled language for deve...</td>\n",
       "      <td>V</td>\n",
       "      <td>1,326</td>\n",
       "      <td>22,167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>serhii-londar /</td>\n",
       "      <td>🚀 Awesome list of open source applications for...</td>\n",
       "      <td>Swift</td>\n",
       "      <td>1,648</td>\n",
       "      <td>24,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PowerShell /</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>C#</td>\n",
       "      <td>3,923</td>\n",
       "      <td>24,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ossu /</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>10,823</td>\n",
       "      <td>74,976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>iptv-org /</td>\n",
       "      <td>Collection of 5000+ publicly available IPTV ch...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>861</td>\n",
       "      <td>27,557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>streamich /</td>\n",
       "      <td>React Hooks — 👍</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1,373</td>\n",
       "      <td>19,578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Azure /</td>\n",
       "      <td>The source for REST API specifications for Mic...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>2,649</td>\n",
       "      <td>1,052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adityatelange /</td>\n",
       "      <td>A fast, clean, responsive Hugo theme</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>230</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reactend /</td>\n",
       "      <td>React renderer to build Node.js server</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flybywiresim /</td>\n",
       "      <td>The A32NX Project is a community driven open s...</td>\n",
       "      <td>Go</td>\n",
       "      <td>466</td>\n",
       "      <td>2,949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dimbreath /</td>\n",
       "      <td>Repository containing the game data for the ga...</td>\n",
       "      <td>Python</td>\n",
       "      <td>20</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hashicorp /</td>\n",
       "      <td>A tool for secrets management, encryption as a...</td>\n",
       "      <td>Kotlin</td>\n",
       "      <td>2,793</td>\n",
       "      <td>20,024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abhishekkrthakur /</td>\n",
       "      <td>Run VSCode (codeserver) on Google Colab or Kag...</td>\n",
       "      <td>Go</td>\n",
       "      <td>144</td>\n",
       "      <td>1,047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>florisboard /</td>\n",
       "      <td>An open-source keyboard for Android. Currently...</td>\n",
       "      <td>Python</td>\n",
       "      <td>48</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>goreleaser /</td>\n",
       "      <td>Deliver Go binaries as fast and easily as poss...</td>\n",
       "      <td>C#</td>\n",
       "      <td>503</td>\n",
       "      <td>7,013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                        Description  \\\n",
       "0         libsdl-org /                           Simple Directmedia Layer   \n",
       "1              Azure /                         Azure Quickstart Templates   \n",
       "2           system76 /              System76 Launch Configurable Keyboard   \n",
       "3        benbjohnson /               Streaming S3 replication for SQLite.   \n",
       "4          mbround18 /      Valheim Docker server with Odin the CLI tool.   \n",
       "5           deepmind /  This repository contains implementations and i...   \n",
       "6       satwikkansal /                              What the f*ck Python?   \n",
       "7              vlang /  Simple, fast, safe, compiled language for deve...   \n",
       "8      serhii-londar /  🚀 Awesome list of open source applications for...   \n",
       "9         PowerShell /                       PowerShell for every system!   \n",
       "10              ossu /  🎓 Path to a free self-taught education in Comp...   \n",
       "11          iptv-org /  Collection of 5000+ publicly available IPTV ch...   \n",
       "12         streamich /                                    React Hooks — 👍   \n",
       "13             Azure /  The source for REST API specifications for Mic...   \n",
       "14     adityatelange /               A fast, clean, responsive Hugo theme   \n",
       "15          reactend /             React renderer to build Node.js server   \n",
       "16      flybywiresim /  The A32NX Project is a community driven open s...   \n",
       "17         Dimbreath /  Repository containing the game data for the ga...   \n",
       "18         hashicorp /  A tool for secrets management, encryption as a...   \n",
       "19  abhishekkrthakur /  Run VSCode (codeserver) on Google Colab or Kag...   \n",
       "20       florisboard /  An open-source keyboard for Android. Currently...   \n",
       "21        goreleaser /  Deliver Go binaries as fast and easily as poss...   \n",
       "\n",
       "            Language Conutrybuted Muted_Star  \n",
       "0                  C           22        420  \n",
       "1         PowerShell       12,234      9,416  \n",
       "2              Shell           14        737  \n",
       "3                 Go           32      1,922  \n",
       "4               Rust           12         70  \n",
       "5   Jupyter Notebook          978      5,055  \n",
       "6             Python        2,095     24,436  \n",
       "7                  V        1,326     22,167  \n",
       "8              Swift        1,648     24,625  \n",
       "9                 C#        3,923     24,249  \n",
       "10        JavaScript       10,823     74,976  \n",
       "11        TypeScript          861     27,557  \n",
       "12        TypeScript        1,373     19,578  \n",
       "13              HTML        2,649      1,052  \n",
       "14        JavaScript          230        507  \n",
       "15        JavaScript            8        162  \n",
       "16                Go          466      2,949  \n",
       "17            Python           20         69  \n",
       "18            Kotlin        2,793     20,024  \n",
       "19                Go          144      1,047  \n",
       "20            Python           48        534  \n",
       "21                C#          503      7,013  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trending_Repository=pd.DataFrame([])\n",
    "Trending_Repository['Name']=Repository_Name[:22]\n",
    "Trending_Repository['Description']=Description[:22]\n",
    "Trending_Repository['Language']=Language[:22]\n",
    "Trending_Repository['Conutrybuted']=Muted[:22]\n",
    "Trending_Repository['Muted_Star']=Muted_Star[:22]\n",
    "Trending_Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_10860\\281109501.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5=\"https://www.billboard.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_Name =[]\n",
    "Singer=[]\n",
    "rank=[]\n",
    "Last_Week=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/nav/ul/li[3]')       # Locating page foe top videos by xpath\n",
    "top100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '1', '1', '2', '5', '5', '1', '8', '3', '10', '9', '12', '13', '2', '6', '8', '15', '18', '3', '12', '5', '6', '23', '2', '25', '9', '27', '6', '1', '29', '31', '32', '24', '9', '6', '25', '37', '15', '39', '40', '13', '39', '43', '1', '29', '1', '47', '25', '2', '50', '51', '47', '53', '54', '53', '56', '57', '58', '39', '60', '61', '62', '63', '64', '65', '34', '52', '2', '58', '53', '71', '72', '22', '74', '75', '45', '46', '59', '42', '37', '81', '82', '83', '42', '8', '86', '73', '88', '48', '82', '91', '92', '87', '62', '62', '96', '54', '62', '95', '10']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "rb=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in rb:\n",
    "    if i.text is None :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "print(len(rank),rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Drivers License', 'Mood', 'Blinding Lights', '34+35', 'Levitating', 'Go Crazy', 'Positions', 'Save Your Tears', 'Holy', 'Whoopty', 'Good Days', 'Lonely', 'What You Know Bout Love', 'Therefore I Am', 'For The Night', 'Bang!', 'Better Together', 'Streets', 'I Hope', 'Body', 'Dakiti', 'Lemonade', 'You Broke Me First.', 'Laugh Now Cry Later', \"My Ex's Best Friend\", 'Wasted On You', \"You're Mines Still\", 'Anyone', 'Willow', 'On Me', 'Good Time', 'Sand In My Boots', 'Throat Baby (Go Baby)', 'Before You Go', '7 Summers', 'Starting Over', 'Back In Blood', 'More Than My Hometown', 'Finesse Out The Gang Way', 'Hole In The Bottle', 'Kings & Queens', 'Best Friend', 'Cry Baby', 'Rockstar', 'Afterglow', 'Dynamite', 'Happy Does', \"Somebody's Problem\", 'Whats Poppin', 'Put Your Records On', 'Damage', 'Without You', \"Should've Ducked\", 'Just The Way', 'Beers And Sunshine', 'Down To One', \"What's Your Country Song\", 'Beat Box', 'Diamonds', 'The Good Ones', 'Golden', 'Buss It', 'Goosebumps', 'Monsters', 'Long Live', 'Tyler Herro', 'Cover Me Up', 'Forever After All', 'Back To The Streets', \"Still Trappin'\", 'Gravity', 'Bichota', 'Bad Boy', 'Baila Conmigo', 'Lady', 'Still Goin Down', '865', 'So Done', 'Warning', 'Holiday', 'Hell Of A View', 'Girl Like Me', \"Momma's House\", 'Big, Big Plans', 'Monster', 'Heat Waves', 'Stay Down', 'Somebody Like That', 'Skin', 'Moonwalking In Calabasas', 'Kanye Krazy', 'Pick Up Your Feelings', 'You Got It', 'One Too Many', 'Backdoor', 'Fake Woke', 'Prisoner', 'Dangerous', 'Almost Maybes', 'Mr. Right Now']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Song_Name \n",
    "son=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in son:\n",
    "    if i.text is None :\n",
    "        Song_Name.append(\"--\") \n",
    "    else:\n",
    "        Song_Name.append(i.text)\n",
    "print(len(Song_Name),Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Olivia Rodrigo', '24kGoldn Featuring iann dior', 'The Weeknd', 'Ariana Grande', 'Dua Lipa Featuring DaBaby', 'Chris Brown & Young Thug', 'Ariana Grande', 'The Weeknd', 'Justin Bieber Featuring Chance The Rapper', 'CJ', 'SZA', 'Justin Bieber & benny blanco', 'Pop Smoke', 'Billie Eilish', 'Pop Smoke Featuring Lil Baby & DaBaby', 'AJR', 'Luke Combs', 'Doja Cat', 'Gabby Barrett Featuring Charlie Puth', 'Megan Thee Stallion', 'Bad Bunny & Jhay Cortez', 'Internet Money & Gunna Featuring Don Toliver & NAV', 'Tate McRae', 'Drake Featuring Lil Durk', 'Machine Gun Kelly X blackbear', 'Morgan Wallen', 'Yung Bleu Featuring Drake', 'Justin Bieber', 'Taylor Swift', 'Lil Baby', 'Niko Moon', 'Morgan Wallen', 'BRS Kash', 'Lewis Capaldi', 'Morgan Wallen', 'Chris Stapleton', 'Pooh Shiesty Featuring Lil Durk', 'Morgan Wallen', 'Lil Durk Featuring Lil Baby', 'Kelsea Ballerini', 'Ava Max', 'Saweetie Featuring Doja Cat', 'Megan Thee Stallion Featuring DaBaby', 'DaBaby Featuring Roddy Ricch', 'Ed Sheeran', 'BTS', 'Kenny Chesney', 'Morgan Wallen', 'Jack Harlow Featuring DaBaby, Tory Lanez & Lil Wayne', 'Ritt Momney', 'H.E.R.', 'The Kid LAROI', 'Lil Durk Featuring Pooh Shiesty', 'Parmalee x Blanco Brown', 'Darius Rucker', 'Luke Bryan', 'Thomas Rhett', 'SpotemGottem', 'Sam Smith', 'Gabby Barrett', 'Harry Styles', 'Erica Banks', 'Travis Scott & HVME', 'All Time Low Featuring Demi Lovato & blackbear', 'Florida Georgia Line', 'Jack Harlow', 'Morgan Wallen', 'Luke Combs', 'Saweetie Featuring Jhene Aiko', 'Lil Durk & King Von', 'Brent Faiyaz & DJ Dahi Featuring Tyler, The Creator', 'Karol G', 'Juice WRLD & Young Thug', 'Selena Gomez With Rauw Alejandro', 'Brett Young', 'Morgan Wallen', 'Morgan Wallen', 'The Kid LAROI', 'Morgan Wallen', 'Lil Nas X', 'Eric Church', 'Black Eyed Peas X Shakira', 'Dustin Lynch', 'Chris Lane', 'Shawn Mendes & Justin Bieber', 'Glass Animals', 'Lil Durk, 6LACK & Young Thug', 'Tenille Arts', 'Sabrina Carpenter', 'DDG', 'Lil Durk', 'Jazmine Sullivan', 'VEDO', 'Keith Urban Duet With P!nk', 'Lil Durk', 'Tom MacDonald', 'Miley Cyrus Featuring Dua Lipa', 'Morgan Wallen', 'Jordan Davis', '21 Savage & Metro Boomin Featuring Drake']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Singer \n",
    "sin=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in sin:\n",
    "    if i.text is None :\n",
    "        Singer.append(\"--\") \n",
    "    else:\n",
    "        Singer.append(i.text)\n",
    "print(len(Singer),Singer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '2', '3', '4', '5', '6', '7', '14', '8', '16', '9', '13', '19', '12', '11', '10', '15', '25', '17', '18', '20', '21', '27', '22', '34', '31', '32', '26', '28', '29', '37', '38', '24', '33', '23', '36', '40', '30', '-', '42', '35', '45', '54', '41', '39', '46', '50', '43', '44', '55', '52', '47', '-', '56', '53', '58', '59', '60', '49', '64', '65', '67', '73', '69', '68', '63', '74', '66', '61', '84', '-', '75', '57', '-', '86', '72', '77', '79', '76', '71', '90', '85', '87', '82', '70', '91', '-', '89', '48', '88', '-', '-', '95', '96', '-', '-', '81', '-', '-', '80']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Last_Week Rank \n",
    "lwr=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lwr:\n",
    "    if i.text is None :\n",
    "        Last_Week.append(\"--\") \n",
    "    else:\n",
    "        Last_Week.append(i.text)\n",
    "print(len(Last_Week),Last_Week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['4', '26', '61', '14', '18', '39', '15', '8', '20', '13', '6', '16', '22', '13', '31', '31', '18', '4', '58', '11', '14', '25', '24', '25', '25', '4', '9', '5', '8', '9', '18', '4', '16', '50', '24', '23', '5', '32', '1', '16', '26', '4', '9', '41', '7', '24', '12', '8', '51', '16', '8', '9', '1', '6', '8', '6', '7', '3', '20', '6', '15', '4', '3', '6', '5', '15', '5', '15', '11', '6', '1', '10', '3', '1', '4', '7', '4', '13', '4', '12', '4', '4', '4', '18', '11', '3', '4', '3', '2', '6', '1', '2', '6', '8', '4', '1', '11', '3', '2', '18']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Weeks_on_board \n",
    "wob=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in wob:\n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\") \n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "print(len(Weeks_on_board),Weeks_on_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Singer / Crew</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Drivers License</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mood</td>\n",
       "      <td>24kGoldn Featuring iann dior</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>34+35</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Fake Woke</td>\n",
       "      <td>Tom MacDonald</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>54</td>\n",
       "      <td>Prisoner</td>\n",
       "      <td>Miley Cyrus Featuring Dua Lipa</td>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>62</td>\n",
       "      <td>Dangerous</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>95</td>\n",
       "      <td>Almost Maybes</td>\n",
       "      <td>Jordan Davis</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>Mr. Right Now</td>\n",
       "      <td>21 Savage &amp; Metro Boomin Featuring Drake</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Peak_rank        Song_Name                             Singer / Crew  \\\n",
       "0          1  Drivers License                            Olivia Rodrigo   \n",
       "1          1             Mood              24kGoldn Featuring iann dior   \n",
       "2          1  Blinding Lights                                The Weeknd   \n",
       "3          2            34+35                             Ariana Grande   \n",
       "4          5       Levitating                 Dua Lipa Featuring DaBaby   \n",
       "..       ...              ...                                       ...   \n",
       "95        96        Fake Woke                             Tom MacDonald   \n",
       "96        54         Prisoner            Miley Cyrus Featuring Dua Lipa   \n",
       "97        62        Dangerous                             Morgan Wallen   \n",
       "98        95    Almost Maybes                              Jordan Davis   \n",
       "99        10    Mr. Right Now  21 Savage & Metro Boomin Featuring Drake   \n",
       "\n",
       "   Last_Week_Rank Weeks_on_board  \n",
       "0               1              4  \n",
       "1               2             26  \n",
       "2               3             61  \n",
       "3               4             14  \n",
       "4               5             18  \n",
       "..            ...            ...  \n",
       "95              -              1  \n",
       "96             81             11  \n",
       "97              -              3  \n",
       "98              -              2  \n",
       "99             80             18  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Song=pd.DataFrame([])\n",
    "Top_Song['Peak_rank']=rank\n",
    "Top_Song['Song_Name']=Song_Name\n",
    "Top_Song['Singer / Crew']=Singer\n",
    "Top_Song['Last_Week_Rank']=Last_Week\n",
    "Top_Song['Weeks_on_board']=Weeks_on_board\n",
    "Top_Song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_10860\\281109501.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_6=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Da Vinci Code,The', 'Harry Potter and the Deathly Hallows', \"Harry Potter and the Philosopher's Stone\", 'Harry Potter and the Order of the Phoenix', 'Fifty Shades of Grey', 'Harry Potter and the Goblet of Fire', 'Harry Potter and the Chamber of Secrets', 'Harry Potter and the Prisoner of Azkaban', 'Angels and Demons', \"Harry Potter and the Half-blood Prince:Children's Edition\", 'Fifty Shades Darker', 'Twilight', 'Girl with the Dragon Tattoo,The:Millennium Trilogy', 'Fifty Shades Freed', 'Lost Symbol,The', 'New Moon', 'Deception Point', 'Eclipse', 'Lovely Bones,The', 'Curious Incident of the Dog in the Night-time,The', 'Digital Fortress', 'Short History of Nearly Everything,A', 'Girl Who Played with Fire,The:Millennium Trilogy', 'Breaking Dawn', 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar', 'Gruffalo,The', \"Jamie's 30-Minute Meals\", 'Kite Runner,The', 'One Day', 'Thousand Splendid Suns,A', \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\", \"Time Traveler's Wife,The\", 'Atonement', \"Bridget Jones's Diary:A Novel\", 'World According to Clarkson,The', \"Captain Corelli's Mandolin\", 'Sound of Laughter,The', 'Life of Pi', 'Billy Connolly', 'Child Called It,A', \"Gruffalo's Child,The\", \"Angela's Ashes:A Memoir of a Childhood\", 'Birdsong', 'Northern Lights:His Dark Materials S.', 'Labyrinth', 'Harry Potter and the Half-blood Prince', 'Help,The', 'Man and Boy', 'Memoirs of a Geisha', \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\", 'Island,The', 'PS, I Love You', 'You are What You Eat:The Plan That Will Change Your Life', 'Shadow of the Wind,The', 'Tales of Beedle the Bard,The', 'Broker,The', \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\", 'Subtle Knife,The:His Dark Materials S.', 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation', \"Delia's How to Cook:(Bk.1)\", 'Chocolat', 'Boy in the Striped Pyjamas,The', \"My Sister's Keeper\", 'Amber Spyglass,The:His Dark Materials S.', 'To Kill a Mockingbird', 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin', 'Dear Fatty', 'Short History of Tractors in Ukrainian,A', 'Hannibal', 'Lord of the Rings,The', 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio', 'Interpretation of Murder,The', 'Sharon Osbourne Extreme:My Autobiography', 'Alchemist,The:A Fable About Following Your Dream', \"At My Mother's Knee ...:and Other Low Joints\", 'Notes from a Small Island', 'Return of the Naked Chef,The', 'Bridget Jones: The Edge of Reason', \"Jamie's Italy\", 'I Can Make You Thin', 'Down Under', 'Summons,The', 'Small Island', 'Nigella Express', 'Brick Lane', \"Memory Keeper's Daughter,The\", 'Room on the Broom', 'About a Boy', 'My Booky Wook', 'God Delusion,The', '\"Beano\" Annual,The', 'White Teeth', 'House at Riverton,The', 'Book Thief,The', 'Nights of Rain and Stars', 'Ghost,The', 'Happy Days with the Naked Chef', 'Hunger Games,The:Hunger Games Trilogy', \"Lost Boy,The:A Foster Child's Search for the Love of a Family\", \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]\n"
     ]
    }
   ],
   "source": [
    "#scraping the Book_name \n",
    "bname=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "for i in bname:\n",
    "    if i.text is None :\n",
    "        Book_name.append(\"--\") \n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "print(len(Book_name),Book_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Brown, Dan', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'James, E. L.', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'Brown, Dan', 'Rowling, J.K.', 'James, E. L.', 'Meyer, Stephenie', 'Larsson, Stieg', 'James, E. L.', 'Brown, Dan', 'Meyer, Stephenie', 'Brown, Dan', 'Meyer, Stephenie', 'Sebold, Alice', 'Haddon, Mark', 'Brown, Dan', 'Bryson, Bill', 'Larsson, Stieg', 'Meyer, Stephenie', 'Carle, Eric', 'Donaldson, Julia', 'Oliver, Jamie', 'Hosseini, Khaled', 'Nicholls, David', 'Hosseini, Khaled', 'Larsson, Stieg', 'Niffenegger, Audrey', 'McEwan, Ian', 'Fielding, Helen', 'Clarkson, Jeremy', 'Bernieres, Louis de', 'Kay, Peter', 'Martel, Yann', 'Stephenson, Pamela', 'Pelzer, Dave', 'Donaldson, Julia', 'McCourt, Frank', 'Faulks, Sebastian', 'Pullman, Philip', 'Mosse, Kate', 'Rowling, J.K.', 'Stockett, Kathryn', 'Parsons, Tony', 'Golden, Arthur', 'McCall Smith, Alexander', 'Hislop, Victoria', 'Ahern, Cecelia', 'McKeith, Gillian', 'Zafon, Carlos Ruiz', 'Rowling, J.K.', 'Grisham, John', 'Atkins, Robert C.', 'Pullman, Philip', 'Truss, Lynne', 'Smith, Delia', 'Harris, Joanne', 'Boyne, John', 'Picoult, Jodi', 'Pullman, Philip', 'Lee, Harper', 'Gray, John', 'French, Dawn', 'Lewycka, Marina', 'Harris, Thomas', 'Tolkien, J. R. R.', 'Moore, Michael', 'Rubenfeld, Jed', 'Osbourne, Sharon', 'Coelho, Paulo', \"O'Grady, Paul\", 'Bryson, Bill', 'Oliver, Jamie', 'Fielding, Helen', 'Oliver, Jamie', 'McKenna, Paul', 'Bryson, Bill', 'Grisham, John', 'Levy, Andrea', 'Lawson, Nigella', 'Ali, Monica', 'Edwards, Kim', 'Donaldson, Julia', 'Hornby, Nick', 'Brand, Russell', 'Dawkins, Richard', '0', 'Smith, Zadie', 'Morton, Kate', 'Zusak, Markus', 'Binchy, Maeve', 'Harris, Robert', 'Oliver, Jamie', 'Collins, Suzanne', 'Pelzer, Dave', 'Oliver, Jamie']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Author_name \n",
    "Auth=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "for i in Auth:\n",
    "    if i.text is None :\n",
    "        Author_name.append(\"--\") \n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "print(len(Author_name),Author_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Crime, Thriller & Adventure', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Romance & Sagas', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Crime, Thriller & Adventure', \"Children's Fiction\", 'Romance & Sagas', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Romance & Sagas', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Popular Science', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Picture Books', 'Picture Books', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Humour: Collections & General', 'General & Literary Fiction', 'Autobiography: General', 'General & Literary Fiction', 'Biography: The Arts', 'Autobiography: General', 'Picture Books', 'Autobiography: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Science Fiction & Fantasy', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'Fitness & Diet', 'General & Literary Fiction', \"Children's Fiction\", 'Crime, Thriller & Adventure', 'Fitness & Diet', 'Young Adult Fiction', 'Usage & Writing Guides', 'Food & Drink: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Popular Culture & Media: General Interest', 'Autobiography: The Arts', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Science Fiction & Fantasy', 'Current Affairs & Issues', 'Crime, Thriller & Adventure', 'Autobiography: The Arts', 'General & Literary Fiction', 'Autobiography: The Arts', 'Travel Writing', 'Food & Drink: General', 'General & Literary Fiction', 'National & Regional Cuisine', 'Fitness & Diet', 'Travel Writing', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'Picture Books', 'General & Literary Fiction', 'Autobiography: The Arts', 'Popular Science', \"Children's Annuals\", 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Food & Drink: General', 'Young Adult Fiction', 'Biography: General', 'Food & Drink: General']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Genre \n",
    "gen=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]\")\n",
    "for i in gen:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "print(len(Genre),Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Transworld', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Random House', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Transworld', 'Bloomsbury', 'Random House', 'Little, Brown Book', 'Quercus', 'Random House', 'Transworld', 'Little, Brown Book', 'Transworld', 'Little, Brown Book', 'Pan Macmillan', 'Random House', 'Transworld', 'Transworld', 'Quercus', 'Little, Brown Book', 'Penguin', 'Pan Macmillan', 'Penguin', 'Bloomsbury', 'Hodder & Stoughton', 'Bloomsbury', 'Quercus', 'Random House', 'Random House', 'Pan Macmillan', 'Penguin', 'Random House', 'Random House', 'Canongate', 'HarperCollins', 'Orion', 'Pan Macmillan', 'HarperCollins', 'Random House', 'Scholastic Ltd.', 'Orion', 'Bloomsbury', 'Penguin', 'HarperCollins', 'Random House', 'Little, Brown Book', 'Headline', 'HarperCollins', 'Penguin', 'Orion', 'Bloomsbury', 'Random House', 'Random House', 'Scholastic Ltd.', 'Profile Books Group', 'Random House', 'Transworld', 'Random House Childrens Books G', 'Hodder & Stoughton', 'Scholastic Ltd.', 'Random House', 'HarperCollins', 'Random House', 'Penguin', 'Random House', 'HarperCollins', 'Penguin', 'Headline', 'Little, Brown Book', 'HarperCollins', 'Transworld', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Transworld', 'Transworld', 'Random House', 'Headline', 'Random House', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Hodder & Stoughton', 'Transworld', 'D.C. Thomson', 'Penguin', 'Pan Macmillan', 'Transworld', 'Orion', 'Random House', 'Penguin', 'Scholastic Ltd.', 'Orion', 'Penguin']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Publisher \n",
    "pub=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]\")\n",
    "for i in pub:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"--\") \n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "print(len(Publisher),Publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['5,094,805', '4,475,152', '4,200,654', '4,179,479', '3,758,936', '3,583,215', '3,484,047', '3,377,906', '3,193,946', '2,950,264', '2,479,784', '2,315,405', '2,233,570', '2,193,928', '2,183,031', '2,152,737', '2,062,145', '2,052,876', '2,005,598', '1,979,552', '1,928,900', '1,852,919', '1,814,784', '1,787,118', '1,783,535', '1,781,269', '1,743,266', '1,629,119', '1,616,068', '1,583,992', '1,555,135', '1,546,886', '1,539,428', '1,508,205', '1,489,403', '1,352,318', '1,310,207', '1,310,176', '1,231,957', '1,217,712', '1,208,711', '1,204,058', '1,184,967', '1,181,503', '1,181,093', '1,153,181', '1,132,336', '1,130,802', '1,126,337', '1,115,549', '1,108,328', '1,107,379', '1,104,403', '1,092,349', '1,090,847', '1,087,262', '1,054,196', '1,037,160', '1,023,688', '1,015,956', '1,009,873', '1,004,414', '1,003,780', '1,002,314', '998,213', '992,846', '986,753', '986,115', '970,509', '967,466', '963,353', '962,515', '959,496', '956,114', '945,640', '931,312', '925,425', '924,695', '906,968', '905,086', '890,847', '869,671', '869,659', '862,602', '856,540', '845,858', '842,535', '828,215', '820,563', '816,907', '816,585', '815,586', '814,370', '809,641', '808,900', '807,311', '794,201', '792,187', '791,507', '791,095']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Volumes_sold \n",
    "vs=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]\")\n",
    "for i in vs:\n",
    "    if i.text is None :\n",
    "        Volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "print(len(Volumes_sold),Volumes_sold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Volumes_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>5,094,805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,475,152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,200,654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,179,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "      <td>Random House</td>\n",
       "      <td>3,758,936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "      <td>Random House</td>\n",
       "      <td>807,311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>794,201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>792,187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>Biography: General</td>\n",
       "      <td>Orion</td>\n",
       "      <td>791,507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>791,095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "                          Genre        Publisher Volumes_sold  \n",
       "0   Crime, Thriller & Adventure       Transworld    5,094,805  \n",
       "1            Children's Fiction       Bloomsbury    4,475,152  \n",
       "2            Children's Fiction       Bloomsbury    4,200,654  \n",
       "3            Children's Fiction       Bloomsbury    4,179,479  \n",
       "4               Romance & Sagas     Random House    3,758,936  \n",
       "..                          ...              ...          ...  \n",
       "95   General & Literary Fiction     Random House      807,311  \n",
       "96        Food & Drink: General          Penguin      794,201  \n",
       "97          Young Adult Fiction  Scholastic Ltd.      792,187  \n",
       "98           Biography: General            Orion      791,507  \n",
       "99        Food & Drink: General          Penguin      791,095  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book=pd.DataFrame([])\n",
    "Book['Book_name']=Book_name\n",
    "Book['Author_name']=Author_name\n",
    "Book['Genre']=Genre\n",
    "Book['Publisher']=Publisher\n",
    "Book['Volumes_sold']=Volumes_sold\n",
    "Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_10860\\281109501.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_7=\"https://www.imdb.com/list/ls095964455/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genres=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Game of Thrones', 'Stranger Things', 'The Walking Dead', '13 Reasons Why', 'The 100', 'Orange Is the New Black', 'Riverdale', \"Grey's Anatomy\", 'The Flash', 'Arrow', 'Money Heist', 'The Big Bang Theory', 'Black Mirror', 'Sherlock', 'Vikings', 'Pretty Little Liars', 'The Vampire Diaries', 'American Horror Story', 'Breaking Bad', 'Lucifer', 'Supernatural', 'Prison Break', 'How to Get Away with Murder', 'Teen Wolf', 'The Simpsons', 'Once Upon a Time', 'Narcos', 'Daredevil', 'Friends', 'How I Met Your Mother', 'Suits', 'Mr. Robot', 'The Originals', 'Supergirl', 'Gossip Girl', 'Sense8', 'Gotham', 'Westworld', 'Jessica Jones', 'Modern Family', 'Rick and Morty', 'Shadowhunters', 'The End of the F***ing World', 'House of Cards', 'Dark', 'Elite', 'Sex Education', 'Shameless', 'New Girl', 'Agents of S.H.I.E.L.D.', 'You', 'Dexter', 'Fear the Walking Dead', 'Family Guy', 'The Blacklist', 'Lost', 'Peaky Blinders', 'House', 'Quantico', 'Orphan Black', 'Homeland', 'Blindspot', \"DC's Legends of Tomorrow\", \"The Handmaid's Tale\", 'Chilling Adventures of Sabrina', 'The Good Doctor', 'Jane the Virgin', 'Glee', 'South Park', 'Brooklyn Nine-Nine', 'Under the Dome', 'The Umbrella Academy', 'True Detective', 'The OA', 'Desperate Housewives', 'Better Call Saul', 'Bates Motel', 'The Punisher', 'Atypical', 'Dynasty', 'This Is Us', 'The Good Place', 'Iron Fist', 'The Rain', 'Mindhunter', 'Revenge', 'Luke Cage', 'Scandal', 'The Defenders', 'Big Little Lies', 'Insatiable', 'The Mentalist', 'The Crown', 'Chernobyl', 'iZombie', 'Reign', 'A Series of Unfortunate Events', 'Criminal Minds', 'Scream: The TV Series', 'The Haunting of Hill House']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Name \n",
    "mname=driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/h3/a\")\n",
    "for i in mname:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "print(len(Name),Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['(2011–2019)', '(2016– )', '(2010– )', '(2017–2020)', '(2014–2020)', '(2013–2019)', '(2017– )', '(2005– )', '(2014– )', '(2012–2020)', '(2017– )', '(2007–2019)', '(2011– )', '(2010–2017)', '(2013–2020)', '(2010–2017)', '(2009–2017)', '(2011– )', '(2008–2013)', '(2016– )', '(2005–2020)', '(2005–2017)', '(2014–2020)', '(2011–2017)', '(1989– )', '(2011–2018)', '(2015–2017)', '(2015–2018)', '(1994–2004)', '(2005–2014)', '(2011–2019)', '(2015–2019)', '(2013–2018)', '(2015–2021)', '(2007–2012)', '(2015–2018)', '(2014–2019)', '(2016– )', '(2015–2019)', '(2009–2020)', '(2013– )', '(2016–2019)', '(2017–2019)', '(2013–2018)', '(2017–2020)', '(2018– )', '(2019– )', '(2011–2021)', '(2011–2018)', '(2013–2020)', '(2018– )', '(2006–2021)', '(2015– )', '(1999– )', '(2013– )', '(2004–2010)', '(2013– )', '(2004–2012)', '(2015–2018)', '(2013–2017)', '(2011–2020)', '(2015–2020)', '(2016– )', '(2017– )', '(2018–2020)', '(2017– )', '(2014–2019)', '(2009–2015)', '(1997– )', '(2013–2022)', '(2013–2015)', '(2019– )', '(2014– )', '(2016–2019)', '(2004–2012)', '(2015–2021)', '(2013–2017)', '(2017–2019)', '(2017–2021)', '(2017– )', '(2016– )', '(2016–2020)', '(2017–2018)', '(2018–2020)', '(2017–2019)', '(2011–2015)', '(2016–2018)', '(2012–2018)', '(2017)', '(2017–2019)', '(2018–2019)', '(2008–2015)', '(2016– )', '(2019)', '(2015–2019)', '(2013–2017)', '(2017–2019)', '(2005–2020)', '(2015–2019)', '(2018)']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Year_span \n",
    "ys=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in ys:\n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text)\n",
    "print(len(Year_span),Year_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Mystery', 'Comedy, Romance', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama', 'Comedy, Drama', 'Comedy', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Crime, Drama, Mystery', 'Drama, Horror, Sci-Fi', 'Animation, Comedy', 'Crime, Drama, Mystery', 'Adventure, Drama, Fantasy', 'Crime, Drama', 'Drama, Mystery', 'Crime, Drama, Mystery', 'Action, Drama, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Crime, Drama', 'Action, Adventure, Drama', 'Drama, Sci-Fi, Thriller', 'Drama, Fantasy, Horror', 'Drama', 'Comedy', 'Comedy, Drama, Music', 'Animation, Comedy', 'Comedy, Crime', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Drama, Fantasy, Mystery', 'Comedy, Drama, Mystery', 'Crime, Drama', 'Drama, Horror, Mystery', 'Action, Crime, Drama', 'Comedy, Drama', 'Drama', 'Comedy, Drama, Romance', 'Comedy, Drama, Fantasy', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Thriller', 'Drama, Mystery, Thriller', 'Action, Crime, Drama', 'Drama, Thriller', 'Action, Adventure, Crime', 'Crime, Drama, Mystery', 'Comedy, Drama, Thriller', 'Crime, Drama, Mystery', 'Biography, Drama, History', 'Drama, History, Thriller', 'Comedy, Crime, Drama', 'Drama, Fantasy', 'Adventure, Comedy, Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Horror', 'Drama, Horror, Mystery']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Genres \n",
    "gnr=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in gnr:\n",
    "    if i.text is None :\n",
    "        Genres.append(\"--\") \n",
    "    else:\n",
    "        Genres.append(i.text)\n",
    "print(len(Genres),Genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['57 min', '51 min', '44 min', '60 min', '43 min', '59 min', '45 min', '41 min', '43 min', '42 min', '70 min', '22 min', '60 min', '88 min', '44 min', '44 min', '43 min', '60 min', '49 min', '42 min', '44 min', '44 min', '43 min', '41 min', '22 min', '60 min', '49 min', '54 min', '22 min', '22 min', '44 min', '49 min', '45 min', '43 min', '42 min', '60 min', '42 min', '62 min', '56 min', '22 min', '23 min', '42 min', '25 min', '51 min', '60 min', '60 min', '45 min', '46 min', '22 min', '45 min', '45 min', '53 min', '44 min', '22 min', '43 min', '44 min', '60 min', '44 min', '42 min', '44 min', '55 min', '42 min', '42 min', '60 min', '60 min', '41 min', '60 min', '44 min', '22 min', '22 min', '43 min', '60 min', '55 min', '60 min', '45 min', '46 min', '45 min', '53 min', '30 min', '42 min', '45 min', '22 min', '55 min', '45 min', '60 min', '44 min', '55 min', '43 min', '50 min', '60 min', '45 min', '43 min', '58 min', '330 min', '42 min', '42 min', '50 min', '42 min', '45 min', '572 min']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Run_time \n",
    "rt=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in rt:\n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)\n",
    "print(len(Run_time),Run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['9.3', '8.7', '8.2', '7.6', '7.6', '8.1', '6.9', '7.6', '7.7', '7.5', '8.3', '8.1', '8.8', '9.1', '8.5', '7.4', '7.7', '8', '9.5', '8.1', '8.4', '8.3', '8.1', '7.6', '8.7', '7.7', '8.8', '8.6', '8.9', '8.3', '8.5', '8.6', '8.2', '6.3', '7.4', '8.3', '7.8', '8.6', '7.9', '8.4', '9.2', '6.6', '8.1', '8.7', '8.8', '7.6', '8.3', '8.6', '7.7', '7.5', '7.7', '8.6', '6.9', '8.1', '8', '8.3', '8.8', '8.7', '6.7', '8.3', '8.3', '7.4', '6.8', '8.4', '7.5', '8.2', '7.8', '6.7', '8.7', '8.4', '6.6', '8', '9', '7.8', '7.5', '8.7', '8.2', '8.5', '8.3', '7.3', '8.7', '8.2', '6.5', '6.3', '8.6', '7.8', '7.3', '7.7', '7.3', '8.5', '6.5', '8.1', '8.7', '9.4', '7.8', '7.5', '7.8', '8.1', '7.2', '8.6']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Ratings \n",
    "rate=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "for i in rate:\n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text)\n",
    "print(len(Ratings),Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1,769,233', '821,635', '853,072', '256,113', '216,348', '278,856', '117,899', '250,776', '305,181', '407,564', '297,878', '722,994', '444,293', '806,945', '431,900', '152,221', '282,921', '277,394', '1,464,320', '232,277', '392,480', '476,193', '129,236', '126,721', '365,570', '208,536', '357,416', '362,447', '827,169', '602,614', '363,473', '333,236', '117,471', '111,147', '154,306', '139,380', '211,829', '428,010', '193,178', '355,035', '375,544', '53,291', '145,873', '466,799', '283,547', '48,131', '158,002', '203,085', '192,273', '199,706', '143,376', '646,228', '112,413', '304,550', '197,104', '495,446', '348,052', '414,569', '57,195', '101,357', '312,706', '66,628', '91,944', '171,996', '77,461', '62,811', '38,745', '136,690', '331,433', '225,169', '101,168', '158,818', '499,232', '90,530', '115,632', '323,679', '96,965', '184,269', '60,233', '14,818', '106,384', '114,922', '114,697', '30,800', '216,929', '112,514', '116,798', '67,246', '90,775', '156,411', '22,561', '165,443', '149,259', '541,112', '60,460', '43,572', '53,853', '161,105', '34,082', '182,229']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Votes \n",
    "v=driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "for i in v:\n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        Votes.append(i.text)\n",
    "print(len(Votes),Votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>57 min</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,769,233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>51 min</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>821,635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010– )</td>\n",
       "      <td>44 min</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.2</td>\n",
       "      <td>853,072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>60 min</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.6</td>\n",
       "      <td>256,113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>43 min</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>216,348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>7.5</td>\n",
       "      <td>43,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>50 min</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>7.8</td>\n",
       "      <td>53,853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>161,105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>45 min</td>\n",
       "      <td>Crime, Drama, Horror</td>\n",
       "      <td>7.2</td>\n",
       "      <td>34,082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>572 min</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>8.6</td>\n",
       "      <td>182,229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span Run_time  \\\n",
       "0                  Game of Thrones  (2011–2019)   57 min   \n",
       "1                  Stranger Things     (2016– )   51 min   \n",
       "2                 The Walking Dead     (2010– )   44 min   \n",
       "3                   13 Reasons Why  (2017–2020)   60 min   \n",
       "4                          The 100  (2014–2020)   43 min   \n",
       "..                             ...          ...      ...   \n",
       "95                           Reign  (2013–2017)   42 min   \n",
       "96  A Series of Unfortunate Events  (2017–2019)   50 min   \n",
       "97                  Criminal Minds  (2005–2020)   42 min   \n",
       "98           Scream: The TV Series  (2015–2019)   45 min   \n",
       "99      The Haunting of Hill House       (2018)  572 min   \n",
       "\n",
       "                      Genres Ratings      Votes  \n",
       "0   Action, Adventure, Drama     9.3  1,769,233  \n",
       "1     Drama, Fantasy, Horror     8.7    821,635  \n",
       "2    Drama, Horror, Thriller     8.2    853,072  \n",
       "3   Drama, Mystery, Thriller     7.6    256,113  \n",
       "4     Drama, Mystery, Sci-Fi     7.6    216,348  \n",
       "..                       ...     ...        ...  \n",
       "95            Drama, Fantasy     7.5     43,572  \n",
       "96  Adventure, Comedy, Drama     7.8     53,853  \n",
       "97     Crime, Drama, Mystery     8.1    161,105  \n",
       "98      Crime, Drama, Horror     7.2     34,082  \n",
       "99    Drama, Horror, Mystery     8.6    182,229  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_Series=pd.DataFrame([])\n",
    "TV_Series['Name']=Name\n",
    "TV_Series['Year_span']=Year_span\n",
    "TV_Series['Run_time']=Run_time\n",
    "TV_Series['Genres']=Genres\n",
    "TV_Series['Ratings']=Ratings\n",
    "TV_Series['Votes']=Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_10860\\281109501.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\c\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_8=\"https://archive.ics.uci.edu/ml/index.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "Attribute_Type=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1 = driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]/a')       # Locating page foe top videos by xpath\n",
    "search_1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 ['Abalone', 'Adult', 'Annealing', 'Anonymous Microsoft Web Data', 'Arrhythmia', 'Artificial Characters', 'Audiology (Original)', 'Audiology (Standardized)', 'Auto MPG', 'Automobile', 'Badges', 'Balance Scale', 'Balloons', 'Breast Cancer', 'Breast Cancer Wisconsin (Original)', 'Breast Cancer Wisconsin (Prognostic)', 'Breast Cancer Wisconsin (Diagnostic)', 'Pittsburgh Bridges', 'Car Evaluation', 'Census Income', 'Chess (King-Rook vs. King-Knight)', 'Chess (King-Rook vs. King-Pawn)', 'Chess (King-Rook vs. King)', 'Chess (Domain Theories)', 'Bach Chorales', 'Connect-4', 'Credit Approval', 'Japanese Credit Screening', 'Computer Hardware', 'Contraceptive Method Choice', 'Covertype', 'Cylinder Bands', 'Dermatology', 'Diabetes', 'DGP2 - The Second Data Generation Program', 'Document Understanding', 'EBL Domain Theories', 'Echocardiogram', 'Ecoli', 'Flags', 'Function Finding', 'Glass Identification', \"Haberman's Survival\", 'Hayes-Roth', 'Heart Disease', 'Hepatitis', 'Horse Colic', 'ICU', 'Image Segmentation', 'Internet Advertisements', 'Ionosphere', 'Iris', 'ISOLET', 'Kinship', 'Labor Relations', 'LED Display Domain', 'Lenses', 'Letter Recognition', 'Liver Disorders', 'Logic Theorist', 'Lung Cancer', 'Lymphography', 'Mechanical Analysis', 'Meta-data', 'Mobile Robots', 'Molecular Biology (Promoter Gene Sequences)', 'Molecular Biology (Protein Secondary Structure)', 'Molecular Biology (Splice-junction Gene Sequences)', \"MONK's Problems\", 'Moral Reasoner', 'Multiple Features', 'Mushroom', 'Musk (Version 1)', 'Musk (Version 2)', 'Nursery', 'Othello Domain Theory', 'Page Blocks Classification', 'Optical Recognition of Handwritten Digits', 'Pen-Based Recognition of Handwritten Digits', 'Post-Operative Patient', 'Primary Tumor', 'Prodigy', 'Qualitative Structure Activity Relationships', 'Quadruped Mammals', 'Servo', 'Shuttle Landing Control', 'Solar Flare', 'Soybean (Large)', 'Soybean (Small)', 'Challenger USA Space Shuttle O-Ring', 'Low Resolution Spectrometer', 'Spambase', 'SPECT Heart', 'SPECTF Heart', 'Sponge', 'Statlog Project', 'Student Loan Relational', 'Teaching Assistant Evaluation', 'Tic-Tac-Toe Endgame', 'Thyroid Disease', 'Trains', 'University', 'Congressional Voting Records', 'Water Treatment Plant', 'Waveform Database Generator (Version 1)', 'Waveform Database Generator (Version 2)', 'Wine', 'Yeast', 'Zoo', 'Undocumented', 'Twenty Newsgroups', 'Australian Sign Language signs', 'Australian Sign Language signs (High Quality)', 'US Census Data (1990)', 'Census-Income (KDD)', 'Coil 1999 Competition Data', 'Corel Image Features', 'E. Coli Genes', 'EEG Database', 'El Nino', 'Entree Chicago Recommendation Data', 'CMU Face Images', 'Insurance Company Benchmark (COIL 2000)', 'Internet Usage Data', 'IPUMS Census Database', 'Japanese Vowels', 'KDD Cup 1998 Data', 'KDD Cup 1999 Data', 'M. Tuberculosis Genes', 'Movie', 'MSNBC.com Anonymous Web Data', 'NSF Research Award Abstracts 1990-2003', 'Pioneer-1 Mobile Robot Data', 'Pseudo Periodic Synthetic Time Series', 'Reuters-21578 Text Categorization Collection', 'Robot Execution Failures', 'Synthetic Control Chart Time Series', 'Syskill and Webert Web Page Ratings', 'UNIX User Data', 'Volcanoes on Venus - JARtool experiment', 'Statlog (Australian Credit Approval)', 'Statlog (German Credit Data)', 'Statlog (Heart)', 'Statlog (Landsat Satellite)', 'Statlog (Image Segmentation)', 'Statlog (Shuttle)', 'Statlog (Vehicle Silhouettes)', 'Connectionist Bench (Nettalk Corpus)', 'Connectionist Bench (Sonar, Mines vs. Rocks)', 'Connectionist Bench (Vowel Recognition - Deterding Data)', 'Economic Sanctions', 'Protein Data', 'Cloud', 'CalIt2 Building People Counts', 'Dodgers Loop Sensor', 'Poker Hand', 'MAGIC Gamma Telescope', 'UJI Pen Characters', 'Mammographic Mass', 'Forest Fires', 'Reuters Transcribed Subset', 'Bag of Words', 'Concrete Compressive Strength', 'Hill-Valley', 'Arcene', 'Dexter', 'Dorothea', 'Gisette', 'Madelon', 'Ozone Level Detection', 'Abscisic Acid Signaling Network', 'Parkinsons', 'Character Trajectories', 'Blood Transfusion Service Center', 'UJI Pen Characters (Version 2)', 'Semeion Handwritten Digit', 'SECOM', 'Plants', 'Libras Movement', 'Concrete Slump Test', 'Communities and Crime', 'Acute Inflammations', 'Wine Quality', 'URL Reputation', 'p53 Mutants', 'Parkinsons Telemonitoring', 'Demospongiae', 'Opinosis Opinion ⁄ Review', 'Breast Tissue', 'Cardiotocography', 'Wall-Following Robot Navigation Data', 'Spoken Arabic Digit', 'Localization Data for Person Activity', 'AutoUniv', 'Steel Plates Faults', 'MiniBooNE particle identification', 'YearPredictionMSD', 'PEMS-SF', 'OpinRank Review Dataset', 'Relative location of CT slices on axial axis', 'Online Handwritten Assamese Characters Dataset', 'PubChem Bioassay Data', 'Record Linkage Comparison Patterns', 'Communities and Crime Unnormalized', 'Vertebral Column', 'EMG Physical Action Data Set', 'Vicon Physical Action Data Set', 'Amazon Commerce reviews set', 'Amazon Access Samples', 'Reuter_50_50', 'Farm Ads', 'DBWorld e-mails', 'KEGG Metabolic Relation Network (Directed)', 'KEGG Metabolic Reaction Network (Undirected)', 'Bank Marketing', 'YouTube Comedy Slam Preference Data', 'Gas Sensor Array Drift Dataset', 'ILPD (Indian Liver Patient Dataset)', 'OPPORTUNITY Activity Recognition', 'Nomao', 'SMS Spam Collection', 'Skin Segmentation', 'Planning Relax', 'PAMAP2 Physical Activity Monitoring', 'Restaurant & consumer data', 'CNAE-9', 'Individual household electric power consumption', 'seeds', 'Northix', 'QtyT40I10D100K', 'Legal Case Reports', 'Human Activity Recognition Using Smartphones', 'One-hundred plant species leaves data set', 'Energy efficiency', 'Yacht Hydrodynamics', 'Fertility', 'Daphnet Freezing of Gait', '3D Road Network (North Jutland, Denmark)', 'ISTANBUL STOCK EXCHANGE', 'Buzz in social media', 'First-order theorem proving', 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)', 'Gas sensor arrays in open sampling settings', 'Climate Model Simulation Crashes', 'MicroMass', 'QSAR biodegradation', 'BLOGGER', 'Daily and Sports Activities', 'User Knowledge Modeling', 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection', 'NYSK', 'Turkiye Student Evaluation', \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\", 'EEG Eye State', 'Physicochemical Properties of Protein Tertiary Structure', 'seismic-bumps', 'banknote authentication', 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat', 'YouTube Multiview Video Games Dataset', 'Gas Sensor Array Drift Dataset at Different Concentrations', 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors', 'SkillCraft1 Master Table Dataset', 'Weight Lifting Exercises monitored with Inertial Measurement Units', 'SML2010', 'Bike Sharing Dataset', 'Predict keywords activities in a online social media', 'Thoracic Surgery Data', 'EMG dataset in Lower Limb', 'SUSY', 'HIGGS', 'Qualitative_Bankruptcy', 'LSVT Voice Rehabilitation', 'Dataset for ADL Recognition with Wrist-worn Accelerometer', 'Wilt', 'User Identification From Walking Activity', 'Activity Recognition from Single Chest-Mounted Accelerometer', 'Leaf', 'Dresses_Attribute_Sales', 'Tamilnadu Electricity Board Hourly Readings', 'Airfoil Self-Noise', 'Wholesale customers', 'Twitter Data set for Arabic Sentiment Analysis', 'Combined Cycle Power Plant', 'Urban Land Cover', 'Diabetes 130-US hospitals for years 1999-2008', 'Bach Choral Harmony', 'StoneFlakes', 'Tennis Major Tournament Match Statistics', 'Parkinson Speech Dataset with Multiple Types of Sound Recordings', 'Gesture Phase Segmentation', 'Perfume Data', 'BlogFeedback', 'REALDISP Activity Recognition Dataset', 'Newspaper and magazine images segmentation dataset', 'AAAI 2014 Accepted Papers', 'Gas sensor array under flow modulation', 'Gas sensor array exposed to turbulent gas mixtures', 'UJIIndoorLoc', 'Sentence Classification', 'Dow Jones Index', 'sEMG for Basic Hand movements', 'AAAI 2013 Accepted Papers', 'Geographical Original of Music', 'Condition Based Maintenance of Naval Propulsion Plants', 'Grammatical Facial Expressions', 'NoisyOffice', 'MHEALTH Dataset', 'Student Performance', 'ElectricityLoadDiagrams20112014', 'Gas sensor array under dynamic gas mixtures', 'microblogPCU', 'Firm-Teacher_Clave-Direction_Classification', 'Dataset for Sensorless Drive Diagnosis', 'TV News Channel Commercial Detection Dataset', 'Phishing Websites', 'Greenhouse Gas Observing Network', 'Diabetic Retinopathy Debrecen Data Set', 'HIV-1 protease cleavage', 'Sentiment Labelled Sentences', 'Online News Popularity', 'Forest type mapping', 'wiki4HE', 'Online Video Characteristics and Transcoding Time Dataset', 'Chronic_Kidney_Disease', 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014', 'Folio', 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015', 'Cuff-Less Blood Pressure Estimation', 'Smartphone-Based Recognition of Human Activities and Postural Transitions', 'Mice Protein Expression', 'UJIIndoorLoc-Mag', 'Heterogeneity Activity Recognition', 'Educational Process Mining (EPM): A Learning Analytics Data Set', 'HEPMASS', 'Indoor User Movement Prediction from RSS data', 'Open University Learning Analytics dataset', 'default of credit card clients', 'Mesothelioma’s disease data set', 'Online Retail', 'SIFT10M', 'GPS Trajectories', 'Detect Malacious Executable(AntiVirus)', 'Occupancy Detection', 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease', 'News Aggregator', 'Air Quality', 'Twin gas sensor arrays', 'Gas sensors for home activity monitoring', 'Facebook Comment Volume Dataset', 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)', 'Polish companies bankruptcy data', 'Activity Recognition system based on Multisensor data fusion (AReM)', 'Dota2 Games Results', 'Facebook metrics', 'UbiqLog (smartphone lifelogging)', 'NIPS Conference Papers 1987-2015', 'HTRU2', 'Drug consumption (quantified)', 'Appliances energy prediction', 'Miskolc IIS Hybrid IPS', 'KDC-4007 dataset Collection', 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone', 'DrivFace', 'Website Phishing', 'YouTube Spam Collection', 'Beijing PM2.5 Data', 'Cargo 2000 Freight Tracking and Tracing', 'Cervical cancer (Risk Factors)', 'Quality Assessment of Digital Colposcopies', 'KASANDR', 'FMA: A Dataset For Music Analysis', 'Air quality', 'Epileptic Seizure Recognition', 'Devanagari Handwritten Character Dataset', 'Stock portfolio performance', 'MoCap Hand Postures', 'Early biomarkers of Parkinson�s disease based on natural connected speech', 'Data for Software Engineering Teamwork Assessment in Education Setting', 'PM2.5 Data of Five Chinese Cities', 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet', 'Sales_Transactions_Dataset_Weekly', 'Las Vegas Strip', 'Eco-hotel', 'MEU-Mobile KSD', 'Crowdsourced Mapping', 'gene expression cancer RNA-Seq', 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer', 'chestnut – LARVIC', 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network', 'Motion Capture Hand Postures', 'Anuran Calls (MFCCs)', 'TTC-3600: Benchmark dataset for Turkish text categorization', 'Gastrointestinal Lesions in Regular Colonoscopy', 'Daily Demand Forecasting Orders', 'Paper Reviews', 'extention of Z-Alizadeh sani dataset', 'Z-Alizadeh Sani', 'Dynamic Features of VirusShare Executables', 'IDA2016Challenge', 'DSRC Vehicle Communications', 'Mturk User-Perceived Clusters over Images', 'Character Font Images', 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels', 'Autistic Spectrum Disorder Screening Data for Children', 'Autistic Spectrum Disorder Screening Data for Adolescent', 'APS Failure at Scania Trucks', 'Wireless Indoor Localization', 'HCC Survival', 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015', 'University of Tehran Question Dataset 2016 (UTQD.2016)', 'Autism Screening Adult', 'Activity recognition with healthy older people using a batteryless wearable sensor', 'Immunotherapy Dataset', 'Cryotherapy Dataset', 'OCT data & Color Fundus Images of Left & Right Eyes', 'Discrete Tone Image Dataset', 'News Popularity in Multiple Social Media Platforms', 'Ultrasonic flowmeter diagnostics', 'ICMLA 2014 Accepted Papers Data Set', 'BLE RSSI Dataset for Indoor localization and Navigation', 'Container Crane Controller Data Set', 'Residential Building Data Set', 'Health News in Twitter', 'chipseq', 'SGEMM GPU kernel performance', 'Repeat Consumption Matrices', 'detection_of_IoT_botnet_attacks_N_BaIoT', 'Absenteeism at work', 'SCADI', 'Condition monitoring of hydraulic systems', 'Carbon Nanotubes', 'Optical Interconnection Network', 'Sports articles for objectivity analysis', 'Breast Cancer Coimbra', 'GNFUV Unmanned Surface Vehicles Sensor Data', 'Dishonest Internet users Dataset', 'Victorian Era Authorship Attribution', 'Simulated Falls and Daily Living Activities Data Set', 'Multimodal Damage Identification for Humanitarian Computing', 'EEG Steady-State Visual Evoked Potential Signals', 'Roman Urdu Data Set', 'Avila', 'PANDOR', 'Drug Review Dataset (Druglib.com)', 'Drug Review Dataset (Drugs.com)', 'Physical Unclonable Functions', 'Superconductivty Data', 'WESAD (Wearable Stress and Affect Detection)', 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2', 'Student Academics Performance', 'Online Shoppers Purchasing Intention Dataset', 'PMU-UD', \"Parkinson's Disease Classification\", 'Electrical Grid Stability Simulated Data', 'Caesarian Section Classification Dataset', 'BAUM-1', 'BAUM-2', 'Audit Data', 'BuddyMove Data Set', 'Real estate valuation data set', 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set', 'Somerville Happiness Survey', '2.4 GHZ Indoor Channel Measurements', 'EMG data for gestures', 'Parking Birmingham', 'Behavior of the urban traffic of the city of Sao Paulo in Brazil', 'Travel Reviews', 'Tarvel Review Ratings', 'Rice Leaf Diseases', 'Gas sensor array temperature modulation', 'Facebook Live Sellers in Thailand', 'Parkinson Dataset with replicated acoustic features', 'Metro Interstate Traffic Volume', 'Query Analytics Workloads Dataset', 'Wave Energy Converters', 'PPG-DaLiA', 'Alcohol QCM Sensor Dataset', 'Divorce Predictors data set', 'Incident management process enriched event log', 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)', 'MEx', 'Beijing Multi-Site Air-Quality Data', 'Online Retail II', 'Hepatitis C Virus (HCV) for Egyptian patients', 'QSAR fish toxicity', 'QSAR aquatic toxicity', 'Human Activity Recognition from Continuous Ambient Sensor Data', 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset', 'QSAR oral toxicity', 'QSAR androgen receptor', 'QSAR Bioconcentration classes dataset', 'QSAR fish bioconcentration factor (BCF)', 'A study of Asian Religious and Biblical Texts', 'Real-time Election Results: Portugal 2019', 'Bias correction of numerical prediction model temperature forecast', 'Bar Crawl: Detecting Heavy Drinking', 'Kitsune Network Attack Dataset', 'Shoulder Implant X-Ray Manufacturer Classification', 'Speaker Accent Recognition', 'Heart failure clinical records', 'Deepfakes: Medical Image Tamper Detection', 'selfBACK', 'South German Credit', 'Exasens', 'Swarm Behaviour', 'Crop mapping using fused optical-radar data set', 'BitcoinHeistRansomwareAddressDataset', 'Facebook Large Page-Page Network', 'Amphibians', 'Early stage diabetes risk prediction dataset.', 'Turkish Spam V01', 'Stock keeping units', 'Demand Forecasting for a store', 'Detect Malware Types', 'Wave Energy Converters', 'Youtube cookery channels viewers comments in Hinglish', 'Pedestrian in Traffic Dataset', 'Cervical Cancer Behavior Risk', 'Sattriya_Dance_Single_Hand_Gestures Dataset', 'Divorce Predictors data set', '3W dataset', 'Malware static and dynamic features VxHeaven and Virus Total', 'Internet Firewall Data', 'User Profiling and Abusive Language Detection Dataset', 'Estimation of obesity levels based on eating habits and physical condition', 'Rice (Cammeo and Osmancik)', 'Vehicle routing and scheduling problems', 'Algerian Forest Fires Dataset', 'Breath Metabolomics', 'Horton General Hospital', 'UrbanGB, urban road accidents coordinates labelled by the urban center', 'Gas Turbine CO and NOx Emission Data Set', 'Activity recognition using wearable physiological measurements', 'clickstream data for online shopping', 'CNNpred: CNN-based stock market prediction using a diverse set of variables', 'Apartment for rent classified', ': Simulated Data set of Iraqi tourism places', 'Nasarian CAD Dataset', 'Monolithic Columns in Troad and Mysia Region', 'Bar Crawl: Detecting Heavy Drinking', 'Seoul Bike Sharing Demand', 'Person Classification Gait Data', 'Shill Bidding Dataset', 'Iranian Churn Dataset', 'Unmanned Aerial Vehicle (UAV) Intrusion Detection', 'Bone marrow transplant: children', 'Exasens', 'COVID-19 Surveillance', 'Refractive errors', 'Shoulder Implant X-Ray Manufacturer Classification', 'CLINC150', 'HCV data', 'Taiwanese Bankruptcy Prediction', 'South German Credit (UPDATE)', 'IIWA14-R820-Gazebo-Dataset-10Trajectories', 'Guitar Chords finger positions', 'Russian Corpus of Biographical Texts', 'Codon usage', 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Dataset_Name \n",
    "dname=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "for i in dname:\n",
    "    if i.text is None :\n",
    "        Dataset_Name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_Name.append(i.text)\n",
    "print(len(Dataset_Name),Dataset_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 ['Data Types', 'Multivariate ', 'Multivariate ', 'Multivariate ', ' ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Univariate, Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Data-Generator ', 'Multivariate ', 'Multivariate ', 'Domain-Theory ', 'Univariate, Time-Series ', 'Multivariate, Spatial ', 'Multivariate ', 'Multivariate, Domain-Theory ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Data-Generator ', ' ', ' ', 'Multivariate ', 'Multivariate ', 'Multivariate ', ' ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Relational ', 'Multivariate ', 'Multivariate, Data-Generator ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Domain-Theory ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Domain-Theory ', 'Sequential, Domain-Theory ', 'Sequential ', 'Sequential, Domain-Theory ', 'Multivariate ', 'Domain-Theory ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Domain-Theory ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Domain-Theory ', 'Domain-Theory ', 'Multivariate, Data-Generator ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', ' ', 'Domain-Theory ', 'Multivariate ', 'Multivariate ', 'Multivariate, Domain-Theory ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Data-Generator ', 'Multivariate, Data-Generator ', 'Multivariate ', 'Multivariate ', 'Multivariate ', ' ', 'Text ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Relational ', 'Multivariate, Time-Series ', 'Spatio-temporal ', 'Transactional, Sequential ', 'Image ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Relational ', 'Multivariate, Relational ', 'Sequential ', 'Text ', 'Multivariate, Time-Series ', 'Univariate, Time-Series ', 'Text ', 'Multivariate, Time-Series ', 'Time-Series ', 'Multivariate, Text ', 'Text, Sequential ', 'Image ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', ' ', 'Domain-Theory ', ' ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential ', 'Multivariate ', 'Multivariate ', 'Text ', 'Text ', 'Multivariate ', 'Sequential ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Time-Series ', 'Multivariate ', 'Multivariate, Sequential ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential ', 'Multivariate, Time-Series ', 'Univariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Text ', 'Domain-Theory ', 'Multivariate, Sequential ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Time-Series ', 'Time-Series ', 'Multivariate, Text, Domain-Theory ', 'Time-Series, Domain-Theory ', 'Multivariate, Text, Domain-Theory ', 'Text ', 'Text ', 'Multivariate, Univariate, Text ', 'Multivariate, Univariate, Text ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Univariate ', 'Multivariate, Text, Domain-Theory ', 'Univariate ', 'Univariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate, Text ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate, Univariate, Text ', 'Sequential ', 'Text ', 'Multivariate, Time-Series ', ' ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Sequential, Text ', 'Multivariate, Univariate, Time-Series ', 'Time-Series, Multivariate ', 'Multivariate ', 'Sequential ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Domain-Theory ', 'Multivariate, Text ', 'Multivariate, Time-Series ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series, Text ', 'Univariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate, Time-Series ', ' ', ' ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Univariate, Sequential, Time-Series ', 'Univariate, Sequential, Time-Series ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Sequential ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Univariate, Domain-Theory ', 'Multivariate ', 'Multivariate, Time-Series ', ' ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate ', 'Text ', 'Time-Series ', 'Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Time-Series ', 'Multivariate, Time-Series ', 'Multivariate, Univariate, Sequential, Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', ' ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Sequential, Time-Series ', 'Multivariate ', 'Multivariate, Sequential, Time-Series, Domain-Theory ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series, Domain-Theory ', 'Multivariate, Time-Series ', 'Multivariate ', 'Time-Series ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Text ', 'Multivariate, Text ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate, Time-Series ', 'Multivariate, Sequential ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series ', ' ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Sequential, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate, Time-Series ', ' ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', ' ', 'Text ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate ', 'Time-Series ', 'Text ', ' ', ' ', 'Multivariate, Time-Series ', 'Multivariate ', 'Sequential, Text ', 'Multivariate, Text ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Text ', ' ', 'Sequential ', 'Univariate ', 'Univariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series, Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Univariate, Domain-Theory ', 'Multivariate ', 'Text ', 'Sequential ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate, Time-Series ', 'Univariate ', 'Multivariate ', 'Multivariate, Text ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Text ', 'Time-Series ', 'Multivariate, Text ', 'Multivariate, Time-Series ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Text ', 'Multivariate, Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Univariate ', 'Multivariate ', 'Multivariate ', 'Univariate ', 'Time-Series ', 'Time-Series ', 'Multivariate ', 'Multivariate, Text ', 'Multivariate ', 'Multivariate ', ' ', 'Multivariate ', 'Time-Series ', 'Multivariate, Univariate, Sequential, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate, Text ', 'Multivariate, Text ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate, Univariate ', 'Multivariate, Sequential ', 'Text ', 'Time-Series ', 'Multivariate, Time-Series ', 'Multivariate, Sequential, Time-Series, Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Text ', 'Multivariate, Time-Series, Text ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series, Text ', 'Multivariate ', 'Multivariate, Text ', 'Multivariate, Sequential, Time-Series ', 'Multivariate, Univariate ', 'Multivariate ', 'Multivariate, Univariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', ' ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate, Time-Series ', 'Univariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Sequential ', 'Sequential, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate, Time-Series ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Multivariate ', 'Text ', 'Multivariate ', 'Multivariate ', 'Multivariate ', ' ', 'Text ', 'Text ', 'Multivariate ', 'Time-Series ']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Data_Type \n",
    "dtype=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "for i in dtype:\n",
    "    if i.text is None :\n",
    "        Data_Type.append(\"--\") \n",
    "    else:\n",
    "        Data_Type.append(i.text)\n",
    "print(len(Data_Type),Data_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 ['Default Task', 'Classification ', 'Classification ', 'Classification ', 'Recommender-Systems ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Regression ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', ' ', ' ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Function-Learning ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Relational-Learning ', ' ', 'Classification ', 'Classification ', 'Classification ', ' ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', ' ', 'Classification ', 'Regression ', 'Classification ', 'Regression ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Clustering ', ' ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', ' ', 'Classification ', 'Classification ', 'Clustering ', 'Classification ', ' ', ' ', ' ', ' ', ' ', 'Recommender-Systems ', 'Classification ', 'Regression, Description ', ' ', ' ', 'Classification ', 'Regression ', 'Classification ', ' ', ' ', ' ', ' ', ' ', ' ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', ' ', 'Classification ', 'Classification ', ' ', ' ', ' ', ' ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', 'Clustering ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Causal-Discovery ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Causal-Discovery ', 'Clustering ', 'Classification, Clustering ', 'Regression ', 'Regression ', 'Classification ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', ' ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Regression, Clustering, Causal-Discovery ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification, Regression, Clustering ', 'Classification, Regression, Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification ', ' ', 'Classification ', 'Regression, Clustering ', 'Classification, Clustering ', 'Classification ', ' ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification, Regression ', 'Regression ', 'Classification, Regression ', 'Classification ', 'Regression, Clustering ', 'Classification, Regression ', 'Regression, Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification ', 'Clustering ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification, Regression, Clustering, Causa ', 'Classification, Clustering ', 'Regression ', 'Classification ', 'Regression ', 'Regression ', ' ', 'Classification ', ' ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification ', 'Classification, Clustering ', 'Classification, Regression, Clustering ', 'Regression ', 'Classification, Clustering ', 'Classification ', 'Regression ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification, Clustering, Causal-Discovery ', 'Classification, Regression, Clustering ', 'Classification, Regression ', 'Classification, Clustering ', 'Classification, Clustering ', 'Regression ', 'Classification ', 'Classification ', 'Clustering ', 'Classification, Regression ', 'Classification, Regression ', 'Classification, Regression ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Clustering ', 'Classification, Regression ', 'Regression ', 'Classification, Clustering ', 'Classification, Regression ', 'Classification ', 'Classification, Regression ', 'Regression, Clustering ', 'Classification, Regression ', 'Classification, Causal-Discovery ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Classification ', 'Regression, Clustering, Causal-Discovery ', 'Regression ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Clustering, Causal-Discovery ', 'Classification, Regression ', 'Classification ', 'Classification, Clustering ', 'Classification, Regression, Clustering ', 'Classification, Clustering ', 'Classification, Regression, Clustering ', 'Classification ', 'Classification ', 'Classification, Regression, Clustering ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Causal-Discovery ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Classification, Regression, Clustering ', 'Classification, Clustering ', 'Regression ', 'Classification, Regression ', 'Classification ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Regression ', 'Causal-Discovery ', 'Clustering ', 'Classification, Clustering ', 'Classification ', 'Regression ', 'Classification, Clustering, Causal-Discovery ', 'Classification, Regression ', 'Classification, Regression, Clustering ', 'Classification, Regression, Clustering ', 'Classification ', 'Classification ', 'Regression ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Causal-Discovery ', 'Classification, Clustering ', 'Regression ', 'Classification, Clustering ', 'Classification ', 'Regression ', 'Classification, Clustering ', 'Classification, Regression ', 'Classification ', 'Regression ', 'Classification, Regression, Clustering ', 'Clustering ', 'Classification, Regression ', ' ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification ', 'Regression ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Classification ', 'Clustering ', 'Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Regression ', 'Classification ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification, Regression ', 'Regression ', 'Clustering ', 'Classification ', 'Regression ', 'Clustering ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification, Regression ', 'Regression ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Regression ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Recommendation ', 'Classification, Regression, Clustering ', 'Classification, Regression, Clustering ', 'Classification ', 'Regression ', 'Classification, Regression ', 'Regression ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Regression, Clustering ', 'Classification, Regression ', 'Classification, Clustering ', 'Classification, Clustering ', 'Classification ', 'Classification, Regression ', 'Clustering ', 'Classification ', 'Regression ', 'Regression, Clustering ', 'Regression ', 'Regression ', 'Classification, Regression, Clustering ', 'Classification ', 'Regression, Clustering ', 'Classification ', 'Classification, Clustering ', 'Regression ', 'Classification, Regression, Clustering ', 'Classification ', 'Regression ', 'Regression ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Regression ', 'Classification, Clustering ', 'Regression ', 'Regression ', 'Classification, Regression ', 'Classification, Clustering, Causal-Discovery ', 'Classification ', 'Classification ', 'Classification, Regression, Clustering ', 'Classification ', 'Classification, Clustering ', 'Classification, Regression, Clustering ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Clustering ', 'Regression ', 'Classification ', 'Regression ', 'Classification ', 'Classification, Regression, Causal-Discovery ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Regression, Clustering ', 'Classification ', 'Clustering ', 'Classification, Regression ', 'Classification, Clustering ', 'Causal-Discovery ', 'Clustering ', 'Regression, Clustering ', 'Classification ', 'Classification, Regression, Clustering ', 'Classification, Regression ', 'Classification, Regression, Clustering ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification, Regression ', 'Regression ', 'Classification ', 'Classification, Clustering ', 'Classification, Regression ', 'Classification ', 'Classification, Regression ', 'Classification, Clustering ', 'Classification ', 'Classification ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ', 'Classification, Regression, Clustering ', 'Regression ', 'Classification ', 'Classification ', 'Classification, Clustering ', 'Classification ']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Task \n",
    "t=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "for i in t:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "print(len(Task),Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 ['Attribute Types', 'Categorical, Integer, Real ', 'Categorical, Integer ', 'Categorical, Integer, Real ', 'Categorical ', 'Categorical, Integer, Real ', 'Categorical, Integer, Real ', 'Categorical ', 'Categorical ', 'Categorical, Real ', 'Categorical, Integer, Real ', ' ', 'Categorical ', 'Categorical ', 'Categorical ', 'Integer ', 'Real ', 'Real ', 'Categorical, Integer ', 'Categorical ', 'Categorical, Integer ', 'Categorical, Integer ', 'Categorical ', 'Categorical, Integer ', ' ', 'Categorical, Integer ', 'Categorical ', 'Categorical, Integer, Real ', 'Categorical, Real, Integer ', 'Integer ', 'Categorical, Integer ', 'Categorical, Integer ', 'Categorical, Integer, Real ', 'Categorical, Integer ', 'Categorical, Integer ', 'Real ', ' ', ' ', 'Categorical, Integer, Real ', 'Real ', 'Categorical, Integer ', 'Real ', 'Real ', 'Integer ', 'Categorical ', 'Categorical, Integer, Real ', 'Categorical, Integer, Real ', 'Categorical, Integer, Real ', 'Real ', 'Real ', 'Categorical, Integer, Real ', 'Integer, Real ', 'Real ', 'Real ', 'Categorical ', 'Categorical, Integer, Real ', 'Categorical ', 'Categorical ', 'Integer ', 'Categorical, Integer, Real ', ' ', 'Integer ', 'Categorical ', 'Categorical, Integer, Real ', 'Categorical, Integer, Real ', 'Categorical, Integer, Real ', 'Categorical ', 'Categorical ', 'Categorical ', 'Categorical ', ' ', 'Integer, Real ', 'Categorical ', 'Integer ', 'Integer ', 'Categorical ', ' ', 'Integer, Real ', 'Integer ', 'Integer ', 'Categorical, Integer ', 'Categorical ', ' ', ' ', 'Real ', 'Categorical, Integer ', 'Categorical ', 'Categorical ', 'Categorical ', 'Categorical ', 'Integer ', 'Integer, Real ', 'Integer, Real ', 'Categorical ', 'Integer ', 'Categorical, Integer ', ' ', ' ', 'Categorical, Integer ', 'Categorical ', 'Categorical, Real ', 'Categorical ', 'Categorical, Integer ', 'Categorical ', 'Integer, Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', 'Categorical, Integer ', ' ', ' ', 'Categorical, Real ', 'Real ', 'Categorical ', 'Categorical, Integer ', 'Categorical, Real ', 'Real ', ' ', 'Categorical, Integer, Real ', 'Integer, Real ', 'Categorical ', 'Integer ', 'Categorical, Integer ', 'Categorical, Integer ', 'Categorical, Integer ', 'Real ', 'Categorical, Integer ', 'Categorical, Integer ', ' ', ' ', 'Categorical ', ' ', 'Categorical, Real ', ' ', 'Categorical ', 'Integer ', 'Real ', 'Categorical ', ' ', ' ', 'Categorical, Integer, Real ', 'Categorical, Integer ', 'Categorical, Real ', 'Integer ', 'Real ', 'Integer ', 'Integer ', 'Categorical ', 'Real ', 'Real ', ' ', ' ', 'Real ', 'Categorical, Integer ', 'Categorical, Integer ', 'Categorical, Integer ', 'Real ', 'Integer ', 'Integer ', 'Real ', ' ', 'Integer ', 'Real ', 'Real ', 'Real ', 'Integer ', 'Integer ', 'Integer ', 'Real ', 'Real ', 'Integer ', 'Real ', 'Real ', 'Real ', 'Integer ', 'Integer ', 'Real ', 'Categorical ', 'Real ', 'Real ', 'Real ', 'Categorical, Integer ', 'Real ', 'Integer, Real ', 'Real ', 'Integer, Real ', 'Integer ', ' ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Categorical, Integer, Real ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', ' ', 'Real ', 'Integer ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', ' ', 'Real ', ' ', ' ', 'Integer, Real ', 'Integer, Real ', 'Real ', ' ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', ' ', 'Integer ', 'Real ', 'Real ', 'Integer, Real ', 'Integer ', ' ', ' ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', 'Integer, Real ', ' ', 'Real ', 'Integer ', 'Real ', ' ', ' ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', 'Integer ', 'Integer, Real ', 'Real ', ' ', 'Integer, Real ', 'Real ', 'Real ', 'Integer, Real ', 'Integer, Real ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', ' ', 'Real ', ' ', ' ', 'Real ', 'Real ', 'Real ', ' ', 'Real ', 'Real ', 'Integer ', ' ', 'Real ', ' ', 'Integer ', ' ', 'Real ', 'Integer, Real ', 'Integer, Real ', 'Real ', 'Integer ', 'Integer, Real ', 'Real ', ' ', ' ', 'Real ', 'Real ', 'Integer, Real ', 'Integer ', 'Integer, Real ', 'Real ', ' ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Integer ', 'Real ', 'Real ', 'Integer, Real ', ' ', 'Real ', 'Real ', 'Integer ', 'Real ', 'Integer, Real ', 'Categorical ', ' ', 'Integer, Real ', ' ', ' ', 'Integer, Real ', 'Real ', 'Real ', ' ', 'Real ', 'Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', 'Integer ', 'Real ', 'Real ', 'Integer ', 'Integer, Real ', 'Real ', 'Integer, Real ', 'Integer ', 'Real ', 'Real ', 'Real ', 'Real ', ' ', 'Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', ' ', 'Integer ', ' ', 'Integer ', 'Real ', 'Real ', 'Real ', 'Integer ', 'Integer ', 'Integer, Real ', 'Real ', 'Integer ', ' ', 'Integer, Real ', 'Integer ', 'Integer, Real ', 'Real ', 'Integer ', 'Real ', 'Real ', 'Integer, Real ', 'Integer ', 'Real ', 'Integer, Real ', 'Integer, Real ', 'Integer, Real ', 'Integer, Real ', 'Integer ', 'Integer, Real ', 'Integer ', ' ', 'Integer, Real ', ' ', 'Real ', 'Real ', ' ', 'Integer ', 'Real ', 'Real ', 'Integer ', 'Real ', 'Integer ', 'Integer ', 'Integer, Real ', 'Integer, Real ', 'Integer ', 'Integer ', 'Real ', 'Integer ', 'Integer, Real ', 'Integer ', 'Integer ', 'Integer ', 'Integer, Real ', 'Real ', 'Integer, Real ', 'Integer ', ' ', 'Integer ', 'Real ', 'Integer, Real ', 'Integer, Real ', 'Real ', ' ', 'Integer, Real ', 'Real ', ' ', 'Integer ', 'Real ', 'Real ', 'Real ', 'Integer ', 'Integer ', 'Real ', 'Real ', 'Integer, Real ', ' ', 'Real ', 'Real ', 'Integer, Real ', 'Integer ', 'Integer ', 'Real ', ' ', ' ', 'Integer ', 'Integer ', 'Integer ', ' ', 'Real ', 'Categorical ', 'Integer ', 'Integer ', 'Integer ', 'Real ', 'Real ', 'Real ', ' ', 'Integer, Real ', ' ', 'Integer, Real ', 'Real ', 'Integer ', ' ', ' ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', 'Integer ', 'Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Integer ', 'Real ', 'Integer ', ' ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Integer ', 'Integer ', 'Integer ', 'Real ', 'Integer, Real ', 'Integer, Real ', 'Integer, Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', ' ', ' ', ' ', 'Integer, Real ', 'Integer ', 'Integer, Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Integer, Real ', 'Integer ', 'Real ', 'Real ', 'Integer, Real ', ' ', 'Integer, Real ', ' ', ' ', 'Integer, Real ', 'Integer ', ' ', 'Real ', ' ', 'Real ', 'Integer ', ' ', 'Integer ', 'Integer, Real ', 'Integer, Real ', ' ', ' ', 'Integer ', 'Real ', 'Integer, Real ', 'Real ', 'Real ', 'Integer ', 'Real ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', ' ', ' ', ' ', 'Real ', 'Real ', 'Integer, Real ', 'Real ', ' ', 'Integer ', 'Real ', 'Integer, Real ', 'Integer ', ' ', 'Integer ', 'Real ', ' ', 'Integer, Real ', 'Integer ', 'Integer, Real ', 'Integer ', ' ', ' ', ' ', 'Real ']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Attribute_Type \n",
    "att=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "for i in att:\n",
    "    if i.text is None :\n",
    "        Attribute_Type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_Type.append(i.text)\n",
    "print(len(Attribute_Type),Attribute_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 ['# Instances', '4177 ', '48842 ', '798 ', '37711 ', '452 ', '6000 ', '226 ', '226 ', '398 ', '205 ', '294 ', '625 ', '16 ', '286 ', '699 ', '198 ', '569 ', '108 ', '1728 ', '48842 ', ' ', '3196 ', '28056 ', ' ', '100 ', '67557 ', '690 ', '125 ', '209 ', '1473 ', '581012 ', '512 ', '366 ', ' ', ' ', ' ', ' ', '132 ', '336 ', '194 ', '352 ', '214 ', '306 ', '160 ', '303 ', '155 ', '368 ', ' ', '2310 ', '3279 ', '351 ', '150 ', '7797 ', '104 ', '57 ', ' ', '24 ', '20000 ', '345 ', ' ', '32 ', '148 ', '209 ', '528 ', ' ', '106 ', '128 ', '3190 ', '432 ', '202 ', '2000 ', '8124 ', '476 ', '6598 ', '12960 ', ' ', '5473 ', '5620 ', '10992 ', '90 ', '339 ', ' ', ' ', ' ', '167 ', '15 ', '1389 ', '307 ', '47 ', '23 ', '531 ', '4601 ', '267 ', '267 ', '76 ', ' ', '1000 ', '151 ', '958 ', '7200 ', '10 ', '285 ', '435 ', '527 ', '5000 ', '5000 ', '178 ', '1484 ', '101 ', ' ', '20000 ', '6650 ', '2565 ', '2458285 ', '299285 ', '340 ', '68040 ', ' ', '122 ', '178080 ', '50672 ', '640 ', '9000 ', '10104 ', '256932 ', '640 ', '191779 ', '4000000 ', ' ', '10000 ', '989818 ', '129000 ', ' ', '100000 ', '21578 ', '463 ', '600 ', '332 ', ' ', ' ', '690 ', '1000 ', '270 ', '6435 ', '2310 ', '58000 ', '946 ', '20008 ', '208 ', '528 ', ' ', ' ', '1024 ', '10080 ', '50400 ', '1025010 ', '19020 ', '1364 ', '961 ', '517 ', '200 ', '8000000 ', '1030 ', '606 ', '900 ', '2600 ', '1950 ', '13500 ', '4400 ', '2536 ', '300 ', '197 ', '2858 ', '748 ', '11640 ', '1593 ', '1567 ', '22632 ', '360 ', '103 ', '1994 ', '120 ', '4898 ', '2396130 ', '16772 ', '5875 ', '503 ', '51 ', '106 ', '2126 ', '5456 ', '8800 ', '164860 ', ' ', '1941 ', '130065 ', '515345 ', '440 ', ' ', '53500 ', '8235 ', ' ', '5749132 ', '2215 ', '310 ', '10000 ', '3000 ', '1500 ', '30000 ', '2500 ', '4143 ', '64 ', '53414 ', '65554 ', '45211 ', '1138562 ', '13910 ', '583 ', '2551 ', '34465 ', '5574 ', '245057 ', '182 ', '3850505 ', '138 ', '1080 ', '2075259 ', '210 ', '115 ', '3960456 ', ' ', '10299 ', '1600 ', '768 ', '308 ', '100 ', '237 ', '434874 ', '536 ', '140000 ', '6118 ', '165632 ', '18000 ', '540 ', '931 ', '1055 ', '100 ', '9120 ', '403 ', '111740 ', '10421 ', '5820 ', '403 ', '14980 ', '45730 ', '2584 ', '1372 ', '306 ', '120000 ', '13910 ', '2747 ', '3395 ', '39242 ', '4137 ', '17389 ', '51 ', '470 ', '132 ', '5000000 ', '11000000 ', '250 ', '126 ', ' ', '4889 ', ' ', ' ', '340 ', '501 ', '45781 ', '1503 ', '440 ', '2000 ', '9568 ', '168 ', '100000 ', '5665 ', '79 ', '127 ', '1040 ', '9900 ', '560 ', '60021 ', '1419 ', '101 ', '399 ', '58 ', '180 ', '21048 ', ' ', '750 ', '3000 ', '150 ', '1059 ', '11934 ', '27965 ', '216 ', '120 ', '649 ', '370 ', '4178504 ', '221579 ', '10800 ', '58509 ', '129685 ', '2456 ', '2921 ', '1151 ', '6590 ', '3000 ', '39797 ', '326 ', '913 ', '168286 ', '400 ', '314080 ', '637 ', '1710671 ', '12000 ', '10929 ', '1080 ', '40000 ', '43930257 ', '230318 ', '10500000 ', '13197 ', ' ', '30000 ', '324 ', '541909 ', '11164866 ', '163 ', '373 ', '20560 ', '40 ', '422937 ', '9358 ', '640 ', '919438 ', '40949 ', '5744 ', '10503 ', '42240 ', '102944 ', '500 ', '9782222 ', '11463 ', '17898 ', '1885 ', '19735 ', '1540 ', '4007 ', '153540 ', '606 ', '1353 ', '1956 ', '43824 ', '3942 ', '858 ', '287 ', '17764280 ', '106574 ', '9358 ', '11500 ', '92000 ', '315 ', '78095 ', '130 ', '74 ', '52854 ', '77 ', '811 ', '504 ', '401 ', '2856 ', '10546 ', '801 ', '1540 ', '1451 ', '1075 ', '78095 ', '7195 ', '3600 ', '76 ', '60 ', '405 ', '303 ', '303 ', '107888 ', '76000 ', '10000 ', '180 ', '745000 ', '12234 ', '292 ', '104 ', '60000 ', '2000 ', '165 ', '217 ', '1175 ', '704 ', '75128 ', '90 ', '90 ', '50 ', '71 ', '93239 ', '540 ', '105 ', '6611 ', '15 ', '372 ', '58000 ', '4960 ', '241600 ', '130000 ', '7062606 ', '740 ', '70 ', '2205 ', '10721 ', '640 ', '1000 ', '116 ', '1672 ', '322 ', '93600 ', '3060 ', '5879 ', '9200 ', '20000 ', '20867 ', ' ', '4143 ', '215063 ', '6000000 ', '21263 ', '63000000 ', '10190 ', '300 ', '12330 ', '5180 ', '756 ', '10000 ', '80 ', '1184 ', '1047 ', '777 ', '249 ', '414 ', ' ', '143 ', '7840 ', '30000 ', '35717 ', '135 ', '980 ', '5456 ', '120 ', '4095000 ', '7051 ', '240 ', '48204 ', '260000 ', '288000 ', '8300000 ', '125 ', '170 ', '141712 ', '3916 ', '6262 ', '420768 ', '1067371 ', '1385 ', '908 ', '546 ', '13956534 ', '15630426 ', '8992 ', '1687 ', '779 ', '1056 ', '590 ', '21643 ', '7750 ', '14057567 ', '27170754 ', '597 ', '329 ', '299 ', '20000 ', '26136 ', '1000 ', '399 ', '24017 ', '325834 ', '2916697 ', '22470 ', '189 ', '520 ', '826 ', '2279 ', '28764 ', '7107 ', '288000 ', '9800 ', '4760 ', '72 ', '1450 ', '170 ', '1984 ', '2955 ', '65532 ', '65919 ', '2111 ', '3810 ', '18 ', '244 ', '104 ', '139 ', '360177 ', '36733 ', '4480 ', '165474 ', '1985 ', '10000 ', '232 ', '150 ', '11 ', '14057567 ', '8760 ', '48 ', '6321 ', '3150 ', '17256 ', '187 ', '399 ', '14 ', '467 ', '597 ', '23700 ', '615 ', '6819 ', '1000 ', ' ', '2633 ', '200 ', '13028 ', '800 ']\n"
     ]
    }
   ],
   "source": [
    "#scraping the No_of_Instances \n",
    "noi=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "for i in noi:\n",
    "    if i.text is None :\n",
    "        No_of_Instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_Instances.append(i.text)\n",
    "print(len(No_of_Instances),No_of_Instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 ['# Attributes', '8 ', '14 ', '38 ', '294 ', '279 ', '7 ', ' ', '69 ', '8 ', '26 ', '1 ', '4 ', '4 ', '9 ', '10 ', '34 ', '32 ', '13 ', '6 ', '14 ', '22 ', '36 ', '6 ', ' ', '6 ', '42 ', '15 ', ' ', '9 ', '9 ', '54 ', '39 ', '33 ', '20 ', ' ', ' ', ' ', '12 ', '8 ', '30 ', ' ', '10 ', '3 ', '5 ', '75 ', '19 ', '27 ', ' ', '19 ', '1558 ', '34 ', '4 ', '617 ', '12 ', '16 ', '7 ', '4 ', '16 ', '7 ', ' ', '56 ', '18 ', '8 ', '22 ', ' ', '58 ', ' ', '61 ', '7 ', ' ', '649 ', '22 ', '168 ', '168 ', '8 ', ' ', '10 ', '64 ', '16 ', '8 ', '17 ', ' ', ' ', '72 ', '4 ', '6 ', '10 ', '35 ', '35 ', '4 ', '102 ', '57 ', '22 ', '44 ', '45 ', ' ', ' ', '5 ', '9 ', '21 ', '32 ', '17 ', '16 ', '38 ', '21 ', '40 ', '13 ', '8 ', '17 ', ' ', ' ', '15 ', '22 ', '68 ', '40 ', '17 ', '89 ', ' ', '4 ', '12 ', ' ', ' ', '86 ', '72 ', '61 ', '12 ', '481 ', '42 ', ' ', ' ', ' ', ' ', ' ', ' ', '5 ', '90 ', ' ', '5 ', ' ', ' ', '14 ', '20 ', '13 ', '36 ', '19 ', '9 ', '18 ', '4 ', '60 ', '10 ', ' ', ' ', '10 ', '4 ', '3 ', '11 ', '11 ', ' ', '6 ', '13 ', ' ', '100000 ', '9 ', '101 ', '10000 ', '20000 ', '100000 ', '5000 ', '500 ', '73 ', '43 ', '23 ', '3 ', '5 ', ' ', '256 ', '591 ', '70 ', '91 ', '10 ', '128 ', '6 ', '12 ', '3231961 ', '5409 ', '26 ', ' ', ' ', '10 ', '23 ', '24 ', '13 ', '8 ', ' ', '27 ', '50 ', '90 ', '138672 ', ' ', '386 ', ' ', ' ', '12 ', '147 ', '6 ', '8 ', '27 ', '10000 ', '20000 ', '10000 ', '54877 ', '4702 ', '24 ', '29 ', '17 ', '3 ', '128 ', '10 ', '242 ', '120 ', ' ', '4 ', '13 ', '52 ', '47 ', '857 ', '9 ', '7 ', '200 ', '4 ', ' ', '561 ', '64 ', '8 ', '7 ', '10 ', '9 ', '4 ', '8 ', '77 ', '51 ', '18 ', '1950000 ', '18 ', '1300 ', '41 ', '6 ', '5625 ', '5 ', ' ', '7 ', '33 ', '5 ', '15 ', '9 ', '19 ', '5 ', '5 ', '1000000 ', '129 ', ' ', '20 ', '152 ', '24 ', '16 ', '35 ', '17 ', '5 ', '18 ', '28 ', '7 ', '309 ', '3 ', '6 ', ' ', ' ', '16 ', '13 ', '5 ', '6 ', '8 ', '2 ', '4 ', '148 ', '55 ', '17 ', '8 ', '42 ', '26 ', '50 ', '2 ', '281 ', '120 ', ' ', '6 ', '120432 ', '150000 ', '529 ', ' ', '16 ', '2500 ', '5 ', '68 ', '16 ', '100 ', '216 ', '23 ', '33 ', '140256 ', '19 ', '20 ', '20 ', '49 ', '12 ', '30 ', '5232 ', '20 ', '1 ', ' ', '61 ', '27 ', '53 ', '11 ', '25 ', '0 ', '20 ', '9 ', '3 ', '561 ', '82 ', '13 ', '16 ', '13 ', '28 ', '4 ', ' ', '24 ', '34 ', '8 ', '128 ', '15 ', '513 ', '7 ', '7 ', '5 ', '15 ', '480000 ', '11 ', '54 ', '561 ', '64 ', '6 ', '116 ', '19 ', ' ', '5812 ', '9 ', '32 ', '29 ', '67 ', ' ', '25 ', '6400 ', '10 ', '5 ', '13 ', '98 ', '36 ', '69 ', '2158859 ', '518 ', '15 ', '179 ', ' ', '12 ', '38 ', '65 ', '102 ', '86 ', '7 ', '53 ', '20 ', '1 ', '71 ', '29 ', '20531 ', '65 ', '3 ', '22 ', '38 ', '22 ', '4814 ', '698 ', '13 ', '10 ', '59 ', '56 ', '482 ', '171 ', '5 ', '500 ', '411 ', '8519 ', '21 ', '21 ', '171 ', '7 ', '49 ', '12 ', '3 ', '21 ', '9 ', '8 ', '7 ', '2 ', '11 ', '11 ', '173 ', '5 ', '15 ', '3 ', '105 ', '25000 ', ' ', '18 ', '21000 ', '115 ', '21 ', '206 ', '43680 ', '8 ', '10 ', '59 ', '10 ', '5 ', '5 ', '1000 ', '138 ', ' ', '16 ', '2 ', '10 ', ' ', '8 ', '6 ', '129 ', '81 ', '12 ', '6 ', '22 ', '18 ', '9 ', '754 ', '14 ', '5 ', ' ', ' ', '18 ', '7 ', '7 ', ' ', '7 ', '5 ', '6 ', '4 ', '18 ', '11 ', '25 ', ' ', '20 ', '12 ', '46 ', '9 ', '8 ', '49 ', '11 ', '8 ', '54 ', '36 ', '3916 ', '710 ', '18 ', '8 ', '29 ', '7 ', '9 ', '37 ', '6 ', '1024 ', '1024 ', '14 ', '7 ', '8265 ', '29 ', '25 ', '3 ', '115 ', '1 ', '12 ', '13 ', '200000 ', '6 ', '21 ', '4 ', '2400 ', '175 ', '10 ', '4714 ', '23 ', '17 ', '2 ', '9 ', '8 ', '280 ', '49 ', '3 ', '14 ', '19 ', ' ', '54 ', '8 ', '1087 ', '12 ', '3 ', '17 ', '8 ', '9 ', '12 ', '1656 ', '6 ', '2 ', '11 ', '533 ', '14 ', '84 ', '22 ', '16 ', '52 ', '19 ', '3 ', '14 ', '321 ', '13 ', '13 ', '55 ', '39 ', '4 ', '7 ', '79 ', '1 ', ' ', '14 ', '96 ', '21 ', ' ', '5 ', '2 ', '69 ', '9 ']\n"
     ]
    }
   ],
   "source": [
    "#scraping the No_of_Attribute \n",
    "noa=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "for i in noa:\n",
    "    if i.text is None :\n",
    "        No_of_Attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_Attribute.append(i.text)\n",
    "print(len(No_of_Attribute),No_of_Attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 ['Year', '1995 ', '1996 ', ' ', '1998 ', '1998 ', '1992 ', '1987 ', '1992 ', '1993 ', '1987 ', '1994 ', '1994 ', ' ', '1988 ', '1992 ', '1995 ', '1995 ', '1990 ', '1997 ', '1996 ', '1988 ', '1989 ', '1994 ', ' ', ' ', '1995 ', ' ', '1992 ', '1987 ', '1997 ', '1998 ', '1995 ', '1998 ', ' ', ' ', '1994 ', ' ', '1989 ', '1996 ', '1990 ', '1990 ', '1987 ', '1999 ', '1989 ', '1988 ', '1988 ', '1989 ', ' ', '1990 ', '1998 ', '1989 ', '1988 ', '1994 ', '1990 ', '1988 ', '1988 ', '1990 ', '1991 ', '1990 ', ' ', '1992 ', '1988 ', '1990 ', '1996 ', '1995 ', '1990 ', ' ', '1992 ', '1992 ', '1994 ', ' ', '1987 ', '1994 ', '1994 ', '1997 ', '1991 ', '1995 ', '1998 ', '1998 ', '1993 ', '1988 ', ' ', ' ', '1992 ', '1993 ', '1988 ', '1989 ', '1988 ', '1987 ', '1993 ', '1988 ', '1999 ', '2001 ', '2001 ', ' ', '1992 ', '1993 ', '1997 ', '1991 ', '1987 ', '1994 ', '1988 ', '1987 ', '1993 ', '1988 ', '1988 ', '1991 ', '1996 ', '1990 ', ' ', '1999 ', '1999 ', '2002 ', ' ', '2000 ', '1999 ', '1999 ', '2001 ', '1999 ', '1999 ', '2000 ', '1999 ', '2000 ', '1999 ', '1999 ', ' ', '1998 ', '1999 ', '2001 ', '1999 ', ' ', '2003 ', '1999 ', '1999 ', '1997 ', '1999 ', '1999 ', '1998 ', ' ', ' ', ' ', '1994 ', ' ', '1993 ', '1990 ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '1989 ', '2006 ', '2006 ', '2007 ', '2007 ', '2007 ', '2007 ', '2008 ', '2008 ', '2008 ', '2007 ', '2008 ', '2008 ', '2008 ', '2008 ', '2008 ', '2008 ', '2008 ', '2008 ', '2008 ', '2008 ', '2008 ', '2009 ', '2008 ', '2008 ', '2008 ', '2009 ', '2009 ', '2009 ', '2009 ', '2009 ', '2009 ', '2010 ', '2009 ', '2010 ', '2010 ', '2010 ', '2010 ', '2010 ', '2010 ', '2010 ', '2010 ', '2010 ', '2010 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2011 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2012 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2013 ', '2014 ', '2013 ', '2013 ', '2013 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2013 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2014 ', '2015 ', '2014 ', '2014 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2014 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2015 ', '2016 ', '2016 ', '2015 ', '2016 ', '2016 ', '2015 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2016 ', '2017 ', '2016 ', '2017 ', '2016 ', '2017 ', '2017 ', '2016 ', '2016 ', '2017 ', '2017 ', '2016 ', '2017 ', '2017 ', '2017 ', '2017 ', '2016 ', '2017 ', '2016 ', '2016 ', '2016 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2016 ', '2016 ', '2016 ', '2016 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2016 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2016 ', '2016 ', '2016 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2017 ', '2016 ', '2018 ', '2018 ', '2016 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2018 ', '2019 ', '2019 ', '2018 ', '2018 ', '2018 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2020 ', '2020 ', '2019 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2019 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2019 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ', '2020 ']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Year \n",
    "y=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]/p\")\n",
    "for i in y:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\") \n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "print(len(Year),Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Default Task</td>\n",
       "      <td>Attribute Types</td>\n",
       "      <td># Instances</td>\n",
       "      <td># Attributes</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Statlog Project</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>76</td>\n",
       "      <td>45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Student Loan Relational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Teaching Assistant Evaluation</td>\n",
       "      <td>Domain-Theory</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1000</td>\n",
       "      <td></td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tic-Tac-Toe Endgame</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Thyroid Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>958</td>\n",
       "      <td>9</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Dataset_Name       Data_Type                  Task  \\\n",
       "0                         Abalone      Data Types          Default Task   \n",
       "1                           Adult   Multivariate        Classification    \n",
       "2                       Annealing   Multivariate        Classification    \n",
       "3    Anonymous Microsoft Web Data   Multivariate        Classification    \n",
       "4                      Arrhythmia                  Recommender-Systems    \n",
       "..                            ...             ...                   ...   \n",
       "95                Statlog Project   Multivariate            Clustering    \n",
       "96        Student Loan Relational                                         \n",
       "97  Teaching Assistant Evaluation  Domain-Theory                          \n",
       "98            Tic-Tac-Toe Endgame   Multivariate        Classification    \n",
       "99                Thyroid Disease   Multivariate        Classification    \n",
       "\n",
       "                 Attribute_Type No_of_Instances No_of_Attribute   Year  \n",
       "0               Attribute Types     # Instances    # Attributes   Year  \n",
       "1   Categorical, Integer, Real            4177               8   1995   \n",
       "2         Categorical, Integer           48842              14   1996   \n",
       "3   Categorical, Integer, Real             798              38          \n",
       "4                  Categorical           37711             294   1998   \n",
       "..                          ...             ...             ...    ...  \n",
       "95        Categorical, Integer              76              45          \n",
       "96                                                               1992   \n",
       "97                                        1000                   1993   \n",
       "98        Categorical, Integer             151               5   1997   \n",
       "99                 Categorical             958               9   1991   \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCI=pd.DataFrame([])\n",
    "UCI['Dataset_Name']=Dataset_Name[:100]\n",
    "UCI['Data_Type']=Data_Type[:100]\n",
    "UCI['Task']=Task[:100]\n",
    "UCI['Attribute_Type']=Attribute_Type[:100]\n",
    "UCI['No_of_Instances']=No_of_Instances[:100]\n",
    "UCI['No_of_Attribute']=No_of_Attribute[:100]\n",
    "UCI['Year']=Year[:100]\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
